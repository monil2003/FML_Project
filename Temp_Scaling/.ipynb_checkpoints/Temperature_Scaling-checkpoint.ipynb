{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Temperature Scaling**"
      ],
      "metadata": {
        "id": "Bac7O1V0gHQH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a039b25-d873-4eec-e6af-3ca7b5a6b9af",
        "id": "evoR3TkHg1c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-classification'...\n",
            "remote: Enumerating objects: 287, done.\u001b[K\n",
            "remote: Total 287 (delta 0), reused 0 (delta 0), pack-reused 287 (from 1)\u001b[K\n",
            "Receiving objects: 100% (287/287), 440.37 KiB | 483.00 KiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bearpaw/pytorch-classification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62ca0d2-2cc5-4f29-b24d-9e82af133c42",
        "id": "60Ublp-ugqg5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c8c52220-d882-4f5a-9d69-d1c9f2e1aaa7",
        "id": "fUTfO4wwgvqR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Project.zip\n",
            "   creating: /content/Project/\n",
            "   creating: /content/Project/resnet164Cifar100/\n",
            "  inflating: /content/Project/resnet164Cifar100/checkpoint.pth.tar  \n",
            "  inflating: /content/Project/resnet164Cifar100/log.eps  \n",
            "  inflating: /content/Project/resnet164Cifar100/log.txt  \n",
            "  inflating: /content/Project/resnet164Cifar100/model_best.pth.tar  \n",
            "   creating: /content/Project/densenet190Cifar100/\n",
            "  inflating: /content/Project/densenet190Cifar100/checkpoint.pth.tar  \n",
            "  inflating: /content/Project/densenet190Cifar100/log.txt  \n",
            "  inflating: /content/Project/densenet190Cifar100/model_best.pth.tar  \n",
            "   creating: /content/Project/WRNCifar100/\n",
            "  inflating: /content/Project/WRNCifar100/checkpoint.pth.tar  \n",
            "  inflating: /content/Project/WRNCifar100/log.eps  \n",
            "  inflating: /content/Project/WRNCifar100/log.txt  \n",
            "  inflating: /content/Project/WRNCifar100/model_best.pth.tar  \n",
            "   creating: /content/Project/zip/\n",
            "  inflating: /content/Project/zip/resnet-110.zip  \n",
            "  inflating: /content/Project/zip/densenet-bc-L190-k40.zip  \n",
            "  inflating: /content/Project/zip/zip.txt  \n",
            "  inflating: /content/Project/zip/WRN-28-10-drop.zip  \n",
            "  inflating: /content/Project/Work.ipynb  \n",
            "   creating: /content/Project/pytorch-classification/\n",
            "   creating: /content/Project/pytorch-classification/.git/\n",
            "   creating: /content/Project/pytorch-classification/.git/hooks/\n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/commit-msg.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/post-update.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/pre-commit.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/pre-push.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/pre-rebase.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/pre-receive.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/push-to-checkout.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/sendemail-validate.sample  \n",
            "  inflating: /content/Project/pytorch-classification/.git/hooks/update.sample  \n",
            "   creating: /content/Project/pytorch-classification/.git/info/\n",
            "  inflating: /content/Project/pytorch-classification/.git/info/exclude  \n",
            "  inflating: /content/Project/pytorch-classification/.git/description  \n",
            "   creating: /content/Project/pytorch-classification/.git/objects/\n",
            "   creating: /content/Project/pytorch-classification/.git/objects/pack/\n",
            "  inflating: /content/Project/pytorch-classification/.git/objects/pack/pack-179c425cbae96e6230184c9bf992ccaf71451a93.pack  \n",
            "  inflating: /content/Project/pytorch-classification/.git/objects/pack/pack-179c425cbae96e6230184c9bf992ccaf71451a93.idx  \n",
            "  inflating: /content/Project/pytorch-classification/.git/objects/pack/pack-179c425cbae96e6230184c9bf992ccaf71451a93.rev  \n",
            "   creating: /content/Project/pytorch-classification/.git/objects/info/\n",
            "   creating: /content/Project/pytorch-classification/.git/refs/\n",
            "   creating: /content/Project/pytorch-classification/.git/refs/heads/\n",
            "  inflating: /content/Project/pytorch-classification/.git/refs/heads/master  \n",
            "   creating: /content/Project/pytorch-classification/.git/refs/tags/\n",
            "   creating: /content/Project/pytorch-classification/.git/refs/remotes/\n",
            "   creating: /content/Project/pytorch-classification/.git/refs/remotes/origin/\n",
            "  inflating: /content/Project/pytorch-classification/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: /content/Project/pytorch-classification/.git/packed-refs  \n",
            "   creating: /content/Project/pytorch-classification/.git/logs/\n",
            "   creating: /content/Project/pytorch-classification/.git/logs/refs/\n",
            "   creating: /content/Project/pytorch-classification/.git/logs/refs/remotes/\n",
            "   creating: /content/Project/pytorch-classification/.git/logs/refs/remotes/origin/\n",
            "  inflating: /content/Project/pytorch-classification/.git/logs/refs/remotes/origin/HEAD  \n",
            "   creating: /content/Project/pytorch-classification/.git/logs/refs/heads/\n",
            "  inflating: /content/Project/pytorch-classification/.git/logs/refs/heads/master  \n",
            "  inflating: /content/Project/pytorch-classification/.git/logs/HEAD  \n",
            "  inflating: /content/Project/pytorch-classification/.git/HEAD  \n",
            "  inflating: /content/Project/pytorch-classification/.git/index  \n",
            "  inflating: /content/Project/pytorch-classification/.git/config  \n",
            "  inflating: /content/Project/pytorch-classification/.gitignore  \n",
            "  inflating: /content/Project/pytorch-classification/.gitmodules  \n",
            "  inflating: /content/Project/pytorch-classification/LICENSE  \n",
            "  inflating: /content/Project/pytorch-classification/README.md  \n",
            "  inflating: /content/Project/pytorch-classification/TRAINING.md  \n",
            "  inflating: /content/Project/pytorch-classification/cifar.py  \n",
            "  inflating: /content/Project/pytorch-classification/imagenet.py  \n",
            "   creating: /content/Project/pytorch-classification/models/\n",
            "  inflating: /content/Project/pytorch-classification/models/__init__.py  \n",
            "   creating: /content/Project/pytorch-classification/models/cifar/\n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__init__.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/alexnet.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/densenet.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/preresnet.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/resnet.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/resnext.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/vgg.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/wrn.py  \n",
            "   creating: /content/Project/pytorch-classification/models/cifar/__pycache__/\n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/__init__.cpython-313.pyc  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/alexnet.cpython-313.pyc  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/vgg.cpython-313.pyc  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/resnet.cpython-313.pyc  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/resnext.cpython-313.pyc  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/wrn.cpython-313.pyc  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/preresnet.cpython-313.pyc  \n",
            "  inflating: /content/Project/pytorch-classification/models/cifar/__pycache__/densenet.cpython-313.pyc  \n",
            "   creating: /content/Project/pytorch-classification/models/imagenet/\n",
            "  inflating: /content/Project/pytorch-classification/models/imagenet/__init__.py  \n",
            "  inflating: /content/Project/pytorch-classification/models/imagenet/resnext.py  \n",
            "   creating: /content/Project/pytorch-classification/models/__pycache__/\n",
            "  inflating: /content/Project/pytorch-classification/models/__pycache__/__init__.cpython-313.pyc  \n",
            "   creating: /content/Project/pytorch-classification/utils/\n",
            "  inflating: /content/Project/pytorch-classification/utils/__init__.py  \n",
            "  inflating: /content/Project/pytorch-classification/utils/eval.py  \n",
            "   creating: /content/Project/pytorch-classification/utils/images/\n",
            "  inflating: /content/Project/pytorch-classification/utils/images/cifar.png  \n",
            "  inflating: /content/Project/pytorch-classification/utils/images/imagenet.png  \n",
            "  inflating: /content/Project/pytorch-classification/utils/logger.py  \n",
            "  inflating: /content/Project/pytorch-classification/utils/misc.py  \n",
            "   creating: /content/Project/pytorch-classification/utils/progress/\n",
            "  inflating: /content/Project/pytorch-classification/utils/visualize.py  \n",
            "   creating: /content/Project/.ipynb_checkpoints/\n",
            "  inflating: /content/Project/.ipynb_checkpoints/Work-checkpoint.ipynb  \n",
            "   creating: /content/Project/resnet110cifar10/\n",
            "  inflating: /content/Project/resnet110cifar10/checkpoint.pth.tar  \n",
            "  inflating: /content/Project/resnet110cifar10/log.eps  \n",
            "  inflating: /content/Project/resnet110cifar10/log.txt  \n",
            "  inflating: /content/Project/resnet110cifar10/model_best.pth.tar  \n",
            "   creating: /content/Project/MobilenetV2_Cars/\n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best.pth  \n",
            "   creating: /content/Project/MobilenetV2_Cars/model_best/\n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data.pkl  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/.format_version  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/.storage_alignment  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/byteorder  \n",
            "   creating: /content/Project/MobilenetV2_Cars/model_best/data/\n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/0  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/1  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/2  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/3  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/4  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/5  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/6  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/7  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/8  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/9  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/10  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/11  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/12  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/13  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/14  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/15  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/16  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/17  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/18  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/19  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/20  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/21  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/22  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/23  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/24  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/25  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/26  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/27  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/28  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/29  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/30  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/31  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/32  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/33  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/34  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/35  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/36  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/37  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/38  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/39  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/40  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/41  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/42  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/43  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/44  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/45  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/46  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/47  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/48  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/49  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/50  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/51  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/52  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/53  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/54  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/55  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/56  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/57  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/58  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/59  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/60  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/61  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/62  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/63  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/64  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/65  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/66  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/67  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/68  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/69  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/70  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/71  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/72  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/73  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/74  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/75  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/76  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/77  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/78  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/79  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/80  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/81  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/82  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/83  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/84  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/85  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/86  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/87  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/88  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/89  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/90  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/91  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/92  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/93  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/94  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/95  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/96  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/97  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/98  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/99  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/100  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/101  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/102  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/103  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/104  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/105  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/106  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/107  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/108  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/109  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/110  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/111  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/112  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/113  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/114  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/115  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/116  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/117  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/118  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/119  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/120  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/121  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/122  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/123  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/124  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/125  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/126  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/127  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/128  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/129  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/130  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/131  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/132  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/133  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/134  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/135  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/136  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/137  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/138  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/139  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/140  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/141  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/142  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/143  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/144  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/145  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/146  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/147  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/148  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/149  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/150  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/151  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/152  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/153  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/154  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/155  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/156  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/157  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/158  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/159  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/160  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/161  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/162  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/163  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/164  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/165  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/166  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/167  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/168  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/169  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/170  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/171  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/172  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/173  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/174  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/175  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/176  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/177  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/178  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/179  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/180  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/181  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/182  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/183  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/184  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/185  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/186  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/187  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/188  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/189  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/190  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/191  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/192  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/193  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/194  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/195  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/196  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/197  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/198  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/199  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/200  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/201  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/202  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/203  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/204  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/205  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/206  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/207  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/208  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/209  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/210  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/211  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/212  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/213  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/214  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/215  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/216  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/217  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/218  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/219  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/220  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/221  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/222  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/223  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/224  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/225  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/226  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/227  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/228  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/229  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/230  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/231  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/232  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/233  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/234  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/235  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/236  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/237  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/238  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/239  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/240  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/241  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/242  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/243  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/244  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/245  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/246  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/247  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/248  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/249  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/250  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/251  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/252  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/253  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/254  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/255  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/256  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/257  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/258  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/259  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/260  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/261  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/262  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/263  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/264  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/265  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/266  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/267  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/268  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/269  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/270  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/271  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/272  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/273  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/274  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/275  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/276  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/277  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/278  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/279  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/280  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/281  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/282  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/283  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/284  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/285  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/286  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/287  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/288  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/289  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/290  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/291  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/292  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/293  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/294  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/295  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/296  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/297  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/298  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/299  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/300  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/301  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/302  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/303  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/304  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/305  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/306  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/307  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/308  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/309  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/310  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/311  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/312  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/data/313  \n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/version  \n",
            "   creating: /content/Project/MobilenetV2_Cars/model_best/.data/\n",
            "  inflating: /content/Project/MobilenetV2_Cars/model_best/.data/serialization_id  \n",
            "   creating: /content/Project/InceptionNetV3_Birds/\n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9.pth  \n",
            "   creating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/\n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data.pkl  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/.format_version  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/.storage_alignment  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/byteorder  \n",
            "   creating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/\n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/0  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/1  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/2  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/3  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/4  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/5  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/6  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/7  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/8  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/9  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/10  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/11  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/12  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/13  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/14  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/15  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/16  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/17  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/18  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/19  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/20  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/21  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/22  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/23  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/24  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/25  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/26  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/27  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/28  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/29  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/30  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/31  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/32  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/33  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/34  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/35  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/36  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/37  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/38  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/39  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/40  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/41  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/42  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/43  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/44  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/45  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/46  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/47  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/48  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/49  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/50  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/51  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/52  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/53  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/54  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/55  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/56  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/57  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/58  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/59  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/60  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/61  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/62  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/63  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/64  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/65  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/66  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/67  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/68  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/69  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/70  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/71  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/72  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/73  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/74  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/75  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/76  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/77  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/78  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/79  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/80  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/81  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/82  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/83  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/84  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/85  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/86  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/87  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/88  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/89  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/90  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/91  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/92  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/93  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/94  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/95  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/96  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/97  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/98  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/99  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/100  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/101  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/102  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/103  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/104  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/105  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/106  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/107  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/108  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/109  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/110  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/111  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/112  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/113  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/114  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/115  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/116  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/117  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/118  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/119  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/120  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/121  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/122  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/123  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/124  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/125  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/126  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/127  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/128  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/129  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/130  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/131  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/132  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/133  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/134  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/135  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/136  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/137  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/138  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/139  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/140  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/141  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/142  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/143  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/144  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/145  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/146  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/147  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/148  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/149  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/150  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/151  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/152  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/153  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/154  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/155  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/156  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/157  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/158  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/159  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/160  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/161  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/162  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/163  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/164  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/165  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/166  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/167  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/168  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/169  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/170  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/171  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/172  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/173  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/174  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/175  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/176  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/177  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/178  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/179  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/180  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/181  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/182  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/183  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/184  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/185  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/186  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/187  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/188  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/189  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/190  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/191  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/192  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/193  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/194  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/195  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/196  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/197  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/198  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/199  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/200  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/201  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/202  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/203  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/204  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/205  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/206  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/207  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/208  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/209  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/210  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/211  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/212  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/213  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/214  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/215  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/216  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/217  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/218  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/219  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/220  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/221  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/222  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/223  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/224  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/225  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/226  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/227  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/228  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/229  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/230  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/231  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/232  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/233  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/234  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/235  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/236  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/237  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/238  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/239  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/240  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/241  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/242  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/243  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/244  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/245  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/246  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/247  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/248  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/249  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/250  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/251  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/252  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/253  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/254  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/255  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/256  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/257  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/258  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/259  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/260  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/261  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/262  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/263  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/264  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/265  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/266  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/267  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/268  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/269  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/270  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/271  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/272  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/273  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/274  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/275  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/276  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/277  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/278  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/279  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/280  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/281  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/282  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/283  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/284  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/285  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/286  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/287  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/288  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/289  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/290  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/291  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/292  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/293  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/294  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/295  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/296  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/297  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/298  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/299  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/300  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/301  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/302  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/303  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/304  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/305  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/306  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/307  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/308  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/309  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/310  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/311  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/312  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/313  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/314  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/315  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/316  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/317  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/318  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/319  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/320  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/321  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/322  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/323  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/324  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/325  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/326  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/327  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/328  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/329  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/330  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/331  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/332  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/333  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/334  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/335  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/336  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/337  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/338  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/339  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/340  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/341  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/342  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/343  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/344  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/345  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/346  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/347  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/348  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/349  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/350  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/351  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/352  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/353  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/354  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/355  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/356  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/357  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/358  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/359  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/360  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/361  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/362  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/363  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/364  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/365  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/366  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/367  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/368  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/369  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/370  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/371  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/372  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/373  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/374  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/375  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/376  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/377  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/378  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/379  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/380  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/381  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/382  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/383  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/384  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/385  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/386  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/387  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/388  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/389  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/390  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/391  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/392  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/393  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/394  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/395  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/396  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/397  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/398  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/399  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/400  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/401  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/402  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/403  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/404  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/405  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/406  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/407  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/408  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/409  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/410  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/411  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/412  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/413  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/414  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/415  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/416  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/417  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/418  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/419  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/420  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/421  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/422  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/423  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/424  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/425  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/426  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/427  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/428  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/429  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/430  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/431  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/432  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/433  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/434  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/435  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/436  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/437  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/438  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/439  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/440  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/441  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/442  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/443  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/444  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/445  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/446  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/447  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/448  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/449  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/450  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/451  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/452  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/453  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/454  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/455  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/456  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/457  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/458  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/459  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/460  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/461  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/462  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/463  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/464  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/465  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/466  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/467  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/468  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/469  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/470  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/471  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/472  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/473  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/474  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/475  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/476  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/477  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/478  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/479  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/480  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/481  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/482  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/483  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/484  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/485  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/486  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/487  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/488  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/489  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/490  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/491  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/492  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/493  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/494  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/495  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/496  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/497  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/498  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/499  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/500  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/501  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/502  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/503  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/504  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/505  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/506  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/507  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/508  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/509  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/510  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/511  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/512  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/513  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/514  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/515  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/516  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/517  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/518  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/519  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/520  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/521  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/522  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/523  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/524  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/525  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/526  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/527  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/528  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/529  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/530  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/531  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/532  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/533  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/534  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/535  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/536  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/537  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/538  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/539  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/540  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/541  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/542  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/543  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/544  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/545  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/546  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/547  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/548  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/549  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/550  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/551  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/552  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/553  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/554  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/555  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/556  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/557  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/558  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/559  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/560  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/561  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/562  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/563  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/564  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/565  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/566  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/567  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/568  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/569  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/570  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/571  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/572  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/573  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/574  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/575  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/576  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/577  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/578  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/data/579  \n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/version  \n",
            "   creating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/.data/\n",
            "  inflating: /content/Project/InceptionNetV3_Birds/inceptionv3_birds9/.data/serialization_id  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/Project.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cifar-100 ~ 4 models**"
      ],
      "metadata": {
        "id": "nDpw714xiK4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObfXTUNBHeGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e6084b-1a74-4abd-90e4-410451fd04af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-classification\n",
            "Using device: cuda\n",
            "\n",
            "Loading and splitting CIFAR-100 data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 169M/169M [00:04<00:00, 34.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully split from original test set:\n",
            "  -> New Validation samples: 5000\n",
            "  -> New Test samples:       5000\n",
            "Successfully imported models from 'models.cifar' directory.\n",
            "Loading checkpoint: /content/Project/resnet164Cifar100/checkpoint.pth.tar\n",
            "\n",
            "============================================================\n",
            " ECE Calibration for: ResNet-164\n",
            "============================================================\n",
            "\n",
            "Test metrics BEFORE scaling (T=1.0)  Acc: 73.14%, Avg Conf: 88.21%, ECE: 15.075%\n",
            " Saved reliability diagram: /content/cifar-100/ResNet-164_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=1.00  ECE=14.212%\n",
            "T=1.06  ECE=13.434%\n",
            "T=1.12  ECE=12.645%\n",
            "T=1.19  ECE=11.848%\n",
            "T=1.25  ECE=11.040%\n",
            "T=1.31  ECE=10.222%\n",
            "T=1.38  ECE=9.395%\n",
            "T=1.44  ECE=8.558%\n",
            "T=1.50  ECE=7.711%\n",
            "T=1.56  ECE=6.855%\n",
            "T=1.62  ECE=5.990%\n",
            "T=1.69  ECE=5.116%\n",
            "T=1.75  ECE=4.264%\n",
            "T=1.81  ECE=3.352%\n",
            "T=1.88  ECE=2.709%\n",
            "T=1.94  ECE=2.326%\n",
            "T=2.00  ECE=2.108%\n",
            "T=2.06  ECE=1.860%\n",
            "T=2.12  ECE=2.595%\n",
            "T=2.19  ECE=3.173%\n",
            "T=2.25  ECE=3.168%\n",
            "T=2.31  ECE=4.074%\n",
            "T=2.38  ECE=5.020%\n",
            "T=2.44  ECE=5.999%\n",
            "T=2.50  ECE=6.941%\n",
            "\n",
            " Best T on Validation Set (Min ECE): 2.06  ECE=1.860%\n",
            " Saved ECE-vs-T curve: /content/cifar-100/ResNet-164_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=2.06)  Acc: 73.14%, Avg Conf: 73.47%, ECE: 1.358%\n",
            "\n",
            " Saved reliability diagram: /content/cifar-100/ResNet-164_reliability_after.png\n",
            "Loading checkpoint: /content/Project/densenet190Cifar100/checkpoint.pth.tar\n",
            "\n",
            "============================================================\n",
            " ECE Calibration for: DenseNet-190\n",
            "============================================================\n",
            "\n",
            "Test metrics BEFORE scaling (T=1.0)  Acc: 82.26%, Avg Conf: 89.55%, ECE: 7.335%\n",
            " Saved reliability diagram: /content/cifar-100/DenseNet-190_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=1.00  ECE=6.589%\n",
            "T=1.06  ECE=5.779%\n",
            "T=1.12  ECE=5.013%\n",
            "T=1.19  ECE=4.328%\n",
            "T=1.25  ECE=3.536%\n",
            "T=1.31  ECE=3.051%\n",
            "T=1.38  ECE=2.863%\n",
            "T=1.44  ECE=3.122%\n",
            "T=1.50  ECE=3.139%\n",
            "T=1.56  ECE=3.628%\n",
            "T=1.62  ECE=4.188%\n",
            "T=1.69  ECE=5.191%\n",
            "T=1.75  ECE=6.022%\n",
            "T=1.81  ECE=7.164%\n",
            "T=1.88  ECE=8.496%\n",
            "T=1.94  ECE=9.861%\n",
            "T=2.00  ECE=11.257%\n",
            "T=2.06  ECE=12.680%\n",
            "T=2.12  ECE=14.129%\n",
            "T=2.19  ECE=15.599%\n",
            "T=2.25  ECE=17.087%\n",
            "T=2.31  ECE=18.590%\n",
            "T=2.38  ECE=20.103%\n",
            "T=2.44  ECE=21.625%\n",
            "T=2.50  ECE=23.150%\n",
            "\n",
            " Best T on Validation Set (Min ECE): 1.38  ECE=2.863%\n",
            " Saved ECE-vs-T curve: /content/cifar-100/DenseNet-190_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=1.38)  Acc: 82.26%, Avg Conf: 83.93%, ECE: 2.877%\n",
            "\n",
            " Saved reliability diagram: /content/cifar-100/DenseNet-190_reliability_after.png\n",
            "\n",
            "============================================================\n",
            " ECE Calibration for: ResNet-56 (Hub)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test metrics BEFORE scaling (T=1.0)  Acc: 67.42%, Avg Conf: 83.29%, ECE: 15.867%\n",
            " Saved reliability diagram: /content/cifar-100/ResNet-56_(Hub)_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=1.00  ECE=16.074%\n",
            "T=1.06  ECE=14.927%\n",
            "T=1.12  ECE=13.749%\n",
            "T=1.19  ECE=12.594%\n",
            "T=1.25  ECE=11.384%\n",
            "T=1.31  ECE=10.152%\n",
            "T=1.38  ECE=8.931%\n",
            "T=1.44  ECE=7.600%\n",
            "T=1.50  ECE=6.398%\n",
            "T=1.56  ECE=5.611%\n",
            "T=1.62  ECE=4.298%\n",
            "T=1.69  ECE=3.509%\n",
            "T=1.75  ECE=2.972%\n",
            "T=1.81  ECE=2.739%\n",
            "T=1.88  ECE=2.704%\n",
            "T=1.94  ECE=3.539%\n",
            "T=2.00  ECE=4.897%\n",
            "T=2.06  ECE=6.356%\n",
            "T=2.12  ECE=7.820%\n",
            "T=2.19  ECE=9.287%\n",
            "T=2.25  ECE=10.753%\n",
            "T=2.31  ECE=12.217%\n",
            "T=2.38  ECE=13.675%\n",
            "T=2.44  ECE=15.124%\n",
            "T=2.50  ECE=16.561%\n",
            "\n",
            " Best T on Validation Set (Min ECE): 1.88  ECE=2.704%\n",
            " Saved ECE-vs-T curve: /content/cifar-100/ResNet-56_(Hub)_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=1.88)  Acc: 67.42%, Avg Conf: 64.96%, ECE: 2.677%\n",
            "\n",
            " Saved reliability diagram: /content/cifar-100/ResNet-56_(Hub)_reliability_after.png\n",
            "Loading checkpoint: /content/Project/WRNCifar100/checkpoint.pth.tar\n",
            "\n",
            "============================================================\n",
            " ECE Calibration for: WideResNet-28-10\n",
            "============================================================\n",
            "\n",
            "Test metrics BEFORE scaling (T=1.0)  Acc: 81.74%, Avg Conf: 87.70%, ECE: 6.450%\n",
            " Saved reliability diagram: /content/cifar-100/WideResNet-28-10_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=1.00  ECE=6.472%\n",
            "T=1.06  ECE=5.480%\n",
            "T=1.12  ECE=4.766%\n",
            "T=1.19  ECE=4.373%\n",
            "T=1.25  ECE=3.876%\n",
            "T=1.31  ECE=3.887%\n",
            "T=1.38  ECE=3.546%\n",
            "T=1.44  ECE=3.897%\n",
            "T=1.50  ECE=4.831%\n",
            "T=1.56  ECE=6.395%\n",
            "T=1.62  ECE=8.114%\n",
            "T=1.69  ECE=9.886%\n",
            "T=1.75  ECE=11.707%\n",
            "T=1.81  ECE=13.570%\n",
            "T=1.88  ECE=15.470%\n",
            "T=1.94  ECE=17.398%\n",
            "T=2.00  ECE=19.346%\n",
            "T=2.06  ECE=21.307%\n",
            "T=2.12  ECE=23.273%\n",
            "T=2.19  ECE=25.235%\n",
            "T=2.25  ECE=27.186%\n",
            "T=2.31  ECE=29.120%\n",
            "T=2.38  ECE=31.028%\n",
            "T=2.44  ECE=32.905%\n",
            "T=2.50  ECE=34.746%\n",
            "\n",
            " Best T on Validation Set (Min ECE): 1.38  ECE=3.546%\n",
            " Saved ECE-vs-T curve: /content/cifar-100/WideResNet-28-10_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=1.38)  Acc: 81.74%, Avg Conf: 79.92%, ECE: 3.531%\n",
            "\n",
            " Saved reliability diagram: /content/cifar-100/WideResNet-28-10_reliability_after.png\n",
            "\n",
            "============================================================\n",
            " ECE Calibration run complete for all models.\n",
            "============================================================\n",
            "\n",
            "==================================================================================================================================\n",
            " Final Calibration Comparison on CIFAR-100 Test Set\n",
            "==================================================================================================================================\n",
            "Model                  |   Accuracy |  ECE (Before) |  ECE (After) |  Avg Conf (Before) |  Avg Conf (After) |  Optimal T\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "ResNet-164             |     73.14% |      15.0748% |      1.3580% |             88.21% |            73.47% |     2.0625\n",
            "DenseNet-190           |     82.26% |       7.3355% |      2.8772% |             89.55% |            83.93% |     1.3750\n",
            "ResNet-56 (Hub)        |     67.42% |      15.8666% |      2.6771% |             83.29% |            64.96% |     1.8750\n",
            "WideResNet-28-10       |     81.74% |       6.4495% |      3.5310% |             87.70% |            79.92% |     1.3750\n",
            "==================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch-classification\n",
        "# -----------------------------\n",
        "# ECE CALIBRATION ON CIFAR-100\n",
        "# -----------------------------\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Temperature grid\n",
        "T_values = np.linspace(1.0, 2.5, num=25)\n",
        "\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# --- Load and Split Data (CORRECTED) ---\n",
        "print(\"\\nLoading and splitting CIFAR-100 data...\")\n",
        "try:\n",
        "    # 1. Load the *original* 10,000-image test set\n",
        "    full_test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "    # 2. Split the 10,000 images into a 5,000-image validation set and a 5,000-image test set\n",
        "    val_size = 5000\n",
        "    test_size = 5000\n",
        "\n",
        "    # Use a fixed generator for reproducible splits\n",
        "    val_dataset, test_dataset = random_split(full_test_dataset, [val_size, test_size],\n",
        "                                             generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    # 3. Create DataLoaders\n",
        "    val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Data successfully split from original test set:\")\n",
        "    print(f\"  -> New Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"  -> New Test samples:       {len(test_dataset)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" ERROR: Could not load CIFAR-100 data. {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def get_predictions(model, loader, device, temp=1.0):\n",
        "    model.eval()\n",
        "    all_conf, all_corr = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x) / temp\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            conf, pred = torch.max(probs, 1)\n",
        "            all_conf.extend(conf.cpu().numpy())\n",
        "            all_corr.extend((pred == y).cpu().numpy())\n",
        "    # Note: Accuracy (corr) is not affected by temp, so acc_b and acc_a will be identical\n",
        "    return np.array(all_conf), np.array(all_corr)\n",
        "\n",
        "def calculate_ece(confidences, correct, n_bins=10):\n",
        "    \"\"\"Calculates the Expected Calibration Error (ECE).\"\"\"\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    ece = 0.0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        prop_in_bin = np.mean(in_bin)\n",
        "        if prop_in_bin > 0:\n",
        "            accuracy_in_bin = np.mean(correct[in_bin])\n",
        "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
        "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "    return ece * 100\n",
        "\n",
        "# ---------------------------\n",
        "# PLOTTING FUNCTIONS\n",
        "# ---------------------------\n",
        "\n",
        "def plot_reliability_diagram(confidences, correct, n_bins, model_name, suffix):\n",
        "    \"\"\"Plots a reliability diagram and saves it to a file.\"\"\"\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "\n",
        "    bin_accs = np.zeros(n_bins)\n",
        "    bin_confs = np.zeros(n_bins)\n",
        "    bin_props = np.zeros(n_bins)\n",
        "\n",
        "    for i, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        bin_props[i] = np.mean(in_bin)\n",
        "        if bin_props[i] > 0:\n",
        "            bin_accs[i] = np.mean(correct[in_bin])\n",
        "            bin_confs[i] = np.mean(confidences[in_bin])\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 7))\n",
        "    bar_width = 1.0 / n_bins\n",
        "    bar_centers = bin_lowers + bar_width / 2\n",
        "    non_empty_mask = bin_props > 0\n",
        "\n",
        "    # ECE bar plot\n",
        "    plt.bar(bar_centers[non_empty_mask], bin_accs[non_empty_mask],\n",
        "            width=bar_width * 0.9, alpha=0.3, color='red',\n",
        "            edgecolor='red', label='Accuracy')\n",
        "    # Gaps (where conf != acc)\n",
        "    plt.bar(bar_centers[non_empty_mask], (bin_confs - bin_accs)[non_empty_mask],\n",
        "            bottom=bin_accs[non_empty_mask],\n",
        "            width=bar_width * 0.9, alpha=0.5, color='blue',\n",
        "            edgecolor='black', label='Confidence Gap')\n",
        "\n",
        "    # Perfect calibration line\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "\n",
        "    plt.xlabel('Confidence')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Reliability Diagram: {model_name} ({suffix})')\n",
        "    plt.legend()\n",
        "    plt.xlim(0, 1)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    save_folder = \"/content/cifar-100\"\n",
        "    os.makedirs(save_folder, exist_ok=True) # Creates the folder if it doesn't exist\n",
        "\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_reliability_{suffix}.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved reliability diagram: {filename}\")\n",
        "\n",
        "def plot_ece_vs_temp(T_values, ece_values, best_T, model_name):\n",
        "    \"\"\"Plots ECE vs. Temperature and saves it to a file.\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(T_values, ece_values, 'o-', label='ECE (%)', color='royalblue')\n",
        "    plt.axvline(best_T, color='red', linestyle='--',\n",
        "                label=f'Min ECE at T={best_T:.2f}')\n",
        "    plt.xlabel('Temperature (T)')\n",
        "    plt.ylabel('Expected Calibration Error (%)')\n",
        "    plt.title(f'ECE vs Temperature (Validation Set): {model_name}')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_folder = \"/content/cifar-100\"\n",
        "    os.makedirs(save_folder, exist_ok=True) # Creates the folder if it doesn't exist\n",
        "\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_ECE_vs_T.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved ECE-vs-T curve: {filename}\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# CHECKPOINT LOADER (FIXED)\n",
        "# ---------------------------\n",
        "def load_checkpoint(model, path, device):\n",
        "    print(f\"Loading checkpoint: {path}\")\n",
        "\n",
        "    try:\n",
        "        ckpt = torch.load(path, map_location=device, weights_only=False)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading checkpoint with weights_only=False: {e}\")\n",
        "        try:\n",
        "            print(\"Attempting fallback with weights_only=True...\")\n",
        "            ckpt = torch.load(path, map_location=device, weights_only=True)\n",
        "        except Exception as e_true:\n",
        "            print(f\"Fallback also failed: {e_true}\")\n",
        "            raise e\n",
        "\n",
        "    if 'state_dict' in ckpt:\n",
        "        state_dict = ckpt['state_dict']\n",
        "    else:\n",
        "        print(\"Warning: 'state_dict' key not found. Assuming checkpoint is the state_dict itself.\")\n",
        "        state_dict = ckpt\n",
        "\n",
        "    new_sd = OrderedDict()\n",
        "    for k,v in state_dict.items():\n",
        "        new_sd[k.replace('module.','')] = v\n",
        "    model.load_state_dict(new_sd)\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# ECE Calibration Function (NOW RETURNS RESULTS)\n",
        "# ---------------------------\n",
        "def run_ece_calibration(model, model_name, n_bins=15):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\" ECE Calibration for: {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # --- Test metrics BEFORE scaling ---\n",
        "    conf_b, corr_b = get_predictions(model, test_loader, device, temp=1.0)\n",
        "    ece_b = calculate_ece(conf_b, corr_b, n_bins=n_bins)\n",
        "    acc_b = np.mean(corr_b) * 100\n",
        "    avg_conf_b = np.mean(conf_b) * 100\n",
        "\n",
        "    print(f\"\\nTest metrics BEFORE scaling (T=1.0)  Acc: {acc_b:.2f}%, Avg Conf: {avg_conf_b:.2f}%, ECE: {ece_b:.3f}%\")\n",
        "    plot_reliability_diagram(conf_b, corr_b, n_bins, model_name, \"before\")\n",
        "\n",
        "\n",
        "    # --- Temperature search on validation set ---\n",
        "    best_ece_val = float('inf')\n",
        "    best_T = None\n",
        "    print(\"\\nValidation set temperature search:\")\n",
        "\n",
        "    ece_values_val = []\n",
        "\n",
        "    for T in T_values:\n",
        "        conf, corr = get_predictions(model, val_loader, device, temp=T)\n",
        "        ece = calculate_ece(conf, corr, n_bins=n_bins)\n",
        "        ece_values_val.append(ece)\n",
        "        print(f\"T={T:.2f}  ECE={ece:.3f}%\")\n",
        "        if ece < best_ece_val:\n",
        "            best_ece_val = ece\n",
        "            best_T = T\n",
        "\n",
        "    print(f\"\\n Best T on Validation Set (Min ECE): {best_T:.2f}  ECE={best_ece_val:.3f}%\")\n",
        "    plot_ece_vs_temp(T_values, ece_values_val, best_T, model_name)\n",
        "\n",
        "\n",
        "    # --- Test metrics AFTER scaling ---\n",
        "    conf_a, corr_a = get_predictions(model, test_loader, device, temp=best_T)\n",
        "    ece_a = calculate_ece(conf_a, corr_a, n_bins=n_bins)\n",
        "    acc_a = np.mean(corr_a) * 100 # Note: acc_a will be identical to acc_b\n",
        "    avg_conf_a = np.mean(conf_a) * 100\n",
        "\n",
        "    print(f\"\\nTest metrics AFTER scaling (T={best_T:.2f})  Acc: {acc_a:.2f}%, Avg Conf: {avg_conf_a:.2f}%, ECE: {ece_a:.3f}%\\n\")\n",
        "    plot_reliability_diagram(conf_a, corr_a, n_bins, model_name, \"after\")\n",
        "\n",
        "    # --- NEW: Return results for final table ---\n",
        "    return {\n",
        "        \"name\": model_name,\n",
        "        \"acc\": acc_a,\n",
        "        \"ece_before\": ece_b,\n",
        "        \"ece_after\": ece_a,\n",
        "        \"conf_before\": avg_conf_b,\n",
        "        \"conf_after\": avg_conf_a,\n",
        "        \"best_T\": best_T\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# RUN ECE CALIBRATION FOR EACH MODEL\n",
        "# -----------------------------\n",
        "\n",
        "# NEW: List to store results from all models\n",
        "all_results = []\n",
        "\n",
        "try:\n",
        "    # ---!!! IMPORT YOUR ACTUAL MODELS HERE ---\n",
        "    from models.cifar import resnet\n",
        "    from models.cifar.densenet import densenet, Bottleneck\n",
        "    from models.cifar.wrn import WideResNet\n",
        "    # -----------------------------------------\n",
        "    print(\"Successfully imported models from 'models.cifar' directory.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"WARNING: Could not import model definitions. Using mocks.\")\n",
        "    class MockModel(nn.Module):\n",
        "        def __init__(self): super().__init__(); self.fc = nn.Linear(3072, 100)\n",
        "        def forward(self, x): return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "    resnet = lambda depth, num_classes, block_name: MockModel()\n",
        "    densenet = lambda depth, num_classes, growthRate, compressionRate, block: MockModel()\n",
        "    WideResNet = lambda depth, num_classes, widen_factor, dropRate: MockModel()\n",
        "    Bottleneck = None\n",
        "\n",
        "\n",
        "try:\n",
        "    model_resnet164 = resnet(depth=164, num_classes=100, block_name='Bottleneck')\n",
        "    path = '/content/Project/resnet164Cifar100/checkpoint.pth.tar'\n",
        "    model_resnet164 = load_checkpoint(model_resnet164, path, device)\n",
        "    # NEW: Capture results\n",
        "    results = run_ece_calibration(model_resnet164, \"ResNet-164\")\n",
        "    all_results.append(results)\n",
        "except Exception as e:\n",
        "    print(f\" Skipping ResNet-164: {e}\")\n",
        "\n",
        "try:\n",
        "    model_densenet = densenet(depth=190, num_classes=100, growthRate=40,\n",
        "                              compressionRate=2, block=Bottleneck)\n",
        "    path = '/content/Project/densenet190Cifar100/checkpoint.pth.tar'\n",
        "    model_densenet = load_checkpoint(model_densenet, path, device)\n",
        "    # NEW: Capture results\n",
        "    results = run_ece_calibration(model_densenet, \"DenseNet-190\")\n",
        "    all_results.append(results)\n",
        "except Exception as e:\n",
        "    print(f\" Skipping DenseNet-190: {e}\")\n",
        "\n",
        "try:\n",
        "    model_hub = torch.hub.load(\"chenyaofo/pytorch-cifar-models\",\n",
        "                               \"cifar100_resnet56\", pretrained=True, trust_repo=True)\n",
        "    # NEW: Capture results\n",
        "    results = run_ece_calibration(model_hub, \"ResNet-56 (Hub)\")\n",
        "    all_results.append(results)\n",
        "except Exception as e:\n",
        "    print(f\" Skipping ResNet-56 (Hub): {e}\")\n",
        "\n",
        "try:\n",
        "    model_wrn = WideResNet(depth=28, num_classes=100, widen_factor=10, dropRate=0.3)\n",
        "    path = '/content/Project/WRNCifar100/checkpoint.pth.tar'\n",
        "    model_wrn = load_checkpoint(model_wrn, path, device)\n",
        "    # NEW: Capture results\n",
        "    results = run_ece_calibration(model_wrn, \"WideResNet-28-10\")\n",
        "    all_results.append(results)\n",
        "except Exception as e:\n",
        "    print(f\" Skipping WRN-28-10: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" ECE Calibration run complete for all models.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# NEW: FINAL COMPARISON TABLE\n",
        "# -----------------------------\n",
        "print(\"\\n\" + \"=\"*130)\n",
        "print(\" Final Calibration Comparison on CIFAR-100 Test Set\")\n",
        "print(\"=\"*130)\n",
        "\n",
        "# Print Header\n",
        "print(f\"{'Model':<22} | {'Accuracy':>10} | {'ECE (Before)':>13} | {'ECE (After)':>12} | {'Avg Conf (Before)':>18} | {'Avg Conf (After)':>17} | {'Optimal T':>10}\")\n",
        "print(\"-\" * 130)\n",
        "\n",
        "# Print results\n",
        "for r in all_results:\n",
        "    print(f\"{r['name']:<22} | {r['acc']:>9.2f}% | {r['ece_before']:>12.4f}% | {r['ece_after']:>11.4f}% | {r['conf_before']:>17.2f}% | {r['conf_after']:>16.2f}% | {r['best_T']:>10.4f}\")\n",
        "\n",
        "print(\"=\" * 130)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cifar-10 ~ 2 Models**"
      ],
      "metadata": {
        "id": "bllpF5ygih1E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIViThy4p4CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ccc9901-affe-4e37-d9c9-0693321c1730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Loading and splitting CIFAR-10 data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:06<00:00, 27.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully split from original CIFAR-10 test set:\n",
            "  -> New Validation samples: 5000\n",
            "  -> New Test samples:       5000\n",
            "\n",
            "--- Running calibration for local ResNet-164 ---\n",
            "Loading checkpoint: /content/Project/resnet110cifar10/model_best.pth.tar\n",
            "\n",
            "============================================================\n",
            " ECE Calibration for: ResNet-164 on CIFAR-10\n",
            "============================================================\n",
            "\n",
            "Test metrics BEFORE scaling  Acc: 93.20%, Avg Conf: 96.69%, ECE: 3.749%\n",
            " Saved reliability diagram: /content/cifar-10/ResNet-164_C10_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=1.00  ECE=3.426%\n",
            "T=1.44  ECE=1.577%\n",
            "T=1.89  ECE=0.864%\n",
            "T=2.33  ECE=3.306%\n",
            "T=2.78  ECE=6.308%\n",
            "T=3.22  ECE=9.693%\n",
            "T=3.67  ECE=13.359%\n",
            "T=4.11  ECE=17.121%\n",
            "T=4.56  ECE=20.984%\n",
            "T=5.00  ECE=24.811%\n",
            "\n",
            " Best T on Validation Set: 1.89  ECE=0.864%\n",
            " Saved ECE-vs-T curve: /content/cifar-10/ResNet-164_C10_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=1.89)  Acc: 93.20%, Avg Conf: 92.68%, ECE: 0.953%\n",
            "\n",
            " Saved reliability diagram: /content/cifar-10/ResNet-164_C10_reliability_after.png\n",
            "\n",
            "--- Running calibration for ResNet-56 (torch.hub) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet56-187c023a.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet56-187c023a.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 3.39M/3.39M [00:00<00:00, 67.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " ECE Calibration for: ResNet-56 (Hub) on CIFAR-10\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test metrics BEFORE scaling  Acc: 94.12%, Avg Conf: 98.07%, ECE: 3.964%\n",
            " Saved reliability diagram: /content/cifar-10/ResNet-56_(Hub)_C10_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=1.00  ECE=3.652%\n",
            "T=1.44  ECE=2.216%\n",
            "T=1.89  ECE=1.506%\n",
            "T=2.33  ECE=4.945%\n",
            "T=2.78  ECE=10.909%\n",
            "T=3.22  ECE=17.710%\n",
            "T=3.67  ECE=24.637%\n",
            "T=4.11  ECE=31.160%\n",
            "T=4.56  ECE=37.032%\n",
            "T=5.00  ECE=42.168%\n",
            "\n",
            " Best T on Validation Set: 1.89  ECE=1.506%\n",
            " Saved ECE-vs-T curve: /content/cifar-10/ResNet-56_(Hub)_C10_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=1.89)  Acc: 94.12%, Avg Conf: 94.00%, ECE: 1.212%\n",
            "\n",
            " Saved reliability diagram: /content/cifar-10/ResNet-56_(Hub)_C10_reliability_after.png\n",
            "\n",
            "==================================================================================================================================\n",
            " Final Calibration Comparison on CIFAR-10 Test Set\n",
            "==================================================================================================================================\n",
            "Model                  |   Accuracy |  ECE (Before) |  ECE (After) |  Avg Conf (Before) |  Avg Conf (After) |  Optimal T\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "ResNet-164             |     93.20% |       3.7487% |      0.9531% |             96.69% |            92.68% |     1.8889\n",
            "ResNet-56 (Hub)        |     94.12% |       3.9644% |      1.2121% |             98.07% |            94.00% |     1.8889\n",
            "==================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# ECE CALIBRATION FOR CIFAR-10 MODELS\n",
        "# -----------------------------\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torchvision import datasets, transforms\n",
        "# from torch.utils.data import DataLoader, random_split\n",
        "# from collections import OrderedDict\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Temperature grid\n",
        "T_values = np.linspace(1.0, 2.5, num=10)\n",
        "\n",
        "# UPDATED: Normalization stats for CIFAR-10\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "# --- Load and Split Data (for CIFAR-10) ---\n",
        "print(\"\\nLoading and splitting CIFAR-10 data...\")\n",
        "try:\n",
        "    # 1. Load the *original* 10,000-image CIFAR-10 test set\n",
        "    full_test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "    # 2. Split the 10,000 images into a validation set and a test set\n",
        "    val_size = 5000\n",
        "    test_size = 5000\n",
        "    val_dataset, test_dataset = random_split(full_test_dataset, [val_size, test_size],\n",
        "                                             generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    # 3. Create DataLoaders\n",
        "    val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Data successfully split from original CIFAR-10 test set:\")\n",
        "    print(f\"  -> New Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"  -> New Test samples:       {len(test_dataset)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" ERROR: Could not load CIFAR-10 data. {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def get_predictions(model, loader, device, temp=1.0):\n",
        "    model.eval()\n",
        "    all_conf, all_corr = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x) / temp\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            conf, pred = torch.max(probs, 1)\n",
        "            all_conf.extend(conf.cpu().numpy())\n",
        "            all_corr.extend((pred == y).cpu().numpy())\n",
        "    return np.array(all_conf), np.array(all_corr)\n",
        "\n",
        "def calculate_ece(confidences, correct, n_bins=15):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    ece = 0.0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        prop_in_bin = np.mean(in_bin)\n",
        "        if prop_in_bin > 0:\n",
        "            accuracy_in_bin = np.mean(correct[in_bin])\n",
        "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
        "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "    return ece * 100\n",
        "\n",
        "# --- Plotting Functions (Updated with save folder) ---\n",
        "\n",
        "def plot_reliability_diagram(confidences, correct, n_bins, model_name, suffix):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    bin_accs, bin_confs, bin_props = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
        "\n",
        "    for i, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        bin_props[i] = np.mean(in_bin)\n",
        "        if bin_props[i] > 0:\n",
        "            bin_accs[i] = np.mean(correct[in_bin])\n",
        "            bin_confs[i] = np.mean(confidences[in_bin])\n",
        "\n",
        "    plt.figure(figsize=(8, 7))\n",
        "    bar_width, bar_centers = 1.0 / n_bins, bin_lowers + 1.0 / (2 * n_bins)\n",
        "    non_empty = bin_props > 0\n",
        "\n",
        "    plt.bar(bar_centers[non_empty], bin_accs[non_empty], width=bar_width*0.9, alpha=0.3, color='red', edgecolor='red', label='Accuracy')\n",
        "    plt.bar(bar_centers[non_empty], (bin_confs - bin_accs)[non_empty], bottom=bin_accs[non_empty], width=bar_width*0.9, alpha=0.5, color='blue', edgecolor='black', label='Confidence Gap')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "\n",
        "    plt.xlabel('Confidence'); plt.ylabel('Accuracy'); plt.title(f'Reliability Diagram: {model_name} ({suffix})')\n",
        "    plt.legend(); plt.xlim(0, 1); plt.ylim(0, 1); plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    save_folder = \"/content/cifar-10\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_C10_reliability_{suffix}.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved reliability diagram: {filename}\")\n",
        "\n",
        "def plot_ece_vs_temp(T_values, ece_values, best_T, model_name):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(T_values, ece_values, 'o-', label='ECE (%)', color='royalblue')\n",
        "    plt.axvline(best_T, color='red', linestyle='--', label=f'Min ECE at T={best_T:.2f}')\n",
        "    plt.xlabel('Temperature (T)'); plt.ylabel('Expected Calibration Error (%)'); plt.title(f'ECE vs Temp (Validation): {model_name}')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6); plt.legend(); plt.tight_layout()\n",
        "\n",
        "    save_folder = \"/content/cifar-10\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_C10_ECE_vs_T.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved ECE-vs-T curve: {filename}\")\n",
        "\n",
        "\n",
        "# --- Checkpoint Loader ---\n",
        "def load_checkpoint(model, path, device):\n",
        "    print(f\"Loading checkpoint: {path}\")\n",
        "    ckpt = torch.load(path, map_location=device, weights_only=False)\n",
        "    state_dict = ckpt.get('state_dict', ckpt)\n",
        "    new_sd = OrderedDict((k.replace('module.', ''), v) for k, v in state_dict.items())\n",
        "    model.load_state_dict(new_sd)\n",
        "    return model\n",
        "\n",
        "# --- Main Calibration Function ---\n",
        "def run_ece_calibration(model, model_name, n_bins=15):\n",
        "    print(\"\\n\" + \"=\"*60); print(f\" ECE Calibration for: {model_name} on CIFAR-10\"); print(\"=\"*60)\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # Before scaling\n",
        "    conf_b, corr_b = get_predictions(model, test_loader, device, temp=1.0)\n",
        "    ece_b = calculate_ece(conf_b, corr_b, n_bins=n_bins)\n",
        "    acc_b = np.mean(corr_b) * 100\n",
        "    avg_conf_b = np.mean(conf_b) * 100\n",
        "    print(f\"\\nTest metrics BEFORE scaling  Acc: {acc_b:.2f}%, Avg Conf: {avg_conf_b:.2f}%, ECE: {ece_b:.3f}%\")\n",
        "    plot_reliability_diagram(conf_b, corr_b, n_bins, model_name, \"before\")\n",
        "\n",
        "    # Temperature search\n",
        "    best_ece_val, best_T, ece_values_val = float('inf'), None, []\n",
        "    print(\"\\nValidation set temperature search:\")\n",
        "    for T in T_values:\n",
        "        conf, corr = get_predictions(model, val_loader, device, temp=T)\n",
        "        ece = calculate_ece(conf, corr, n_bins=n_bins)\n",
        "        ece_values_val.append(ece)\n",
        "        print(f\"T={T:.2f}  ECE={ece:.3f}%\")\n",
        "        if ece < best_ece_val:\n",
        "            best_ece_val, best_T = ece, T\n",
        "\n",
        "    print(f\"\\n Best T on Validation Set: {best_T:.2f}  ECE={best_ece_val:.3f}%\")\n",
        "    plot_ece_vs_temp(T_values, ece_values_val, best_T, model_name)\n",
        "\n",
        "    # After scaling\n",
        "    conf_a, corr_a = get_predictions(model, test_loader, device, temp=best_T)\n",
        "    ece_a = calculate_ece(conf_a, corr_a, n_bins=n_bins)\n",
        "    acc_a = np.mean(corr_a) * 100\n",
        "    avg_conf_a = np.mean(conf_a) * 100\n",
        "    print(f\"\\nTest metrics AFTER scaling (T={best_T:.2f})  Acc: {acc_a:.2f}%, Avg Conf: {avg_conf_a:.2f}%, ECE: {ece_a:.3f}%\\n\")\n",
        "    plot_reliability_diagram(conf_a, corr_a, n_bins, model_name, \"after\")\n",
        "\n",
        "    return {\"name\": model_name, \"acc\": acc_a, \"ece_before\": ece_b, \"ece_after\": ece_a,\n",
        "            \"conf_before\": avg_conf_b, \"conf_after\": avg_conf_a, \"best_T\": best_T}\n",
        "\n",
        "# =============================================\n",
        "# --- RUN CALIBRATION FOR CIFAR-10 MODELS ---\n",
        "# =============================================\n",
        "all_results = []\n",
        "\n",
        "# --- 1. ResNet-164 ---\n",
        "try:\n",
        "    from models.cifar import resnet\n",
        "    print(\"\\n--- Running calibration for local ResNet-164 ---\")\n",
        "    model_resnet164 = resnet(depth=164, num_classes=10, block_name='Bottleneck')\n",
        "    path = '/content/Project/resnet110cifar10/model_best.pth.tar'\n",
        "    model_resnet164 = load_checkpoint(model_resnet164, path, device)\n",
        "    results = run_ece_calibration(model_resnet164, \"ResNet-164\")\n",
        "    all_results.append(results)\n",
        "except Exception as e:\n",
        "    print(f\" Skipping local ResNet-164: {e}\")\n",
        "\n",
        "# --- 2. ResNet-56 from torch.hub ---\n",
        "try:\n",
        "    print(\"\\n--- Running calibration for ResNet-56 (torch.hub) ---\")\n",
        "    model_hub = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet56\", pretrained=True, trust_repo=True)\n",
        "    results = run_ece_calibration(model_hub, \"ResNet-56 (Hub)\")\n",
        "    all_results.append(results)\n",
        "except Exception as e:\n",
        "    print(f\" Skipping ResNet-56 (Hub): {e}\")\n",
        "\n",
        "# --- FINAL COMPARISON TABLE ---\n",
        "if all_results:\n",
        "    print(\"\\n\" + \"=\"*130)\n",
        "    print(\" Final Calibration Comparison on CIFAR-10 Test Set\")\n",
        "    print(\"=\"*130)\n",
        "    print(f\"{'Model':<22} | {'Accuracy':>10} | {'ECE (Before)':>13} | {'ECE (After)':>12} | {'Avg Conf (Before)':>18} | {'Avg Conf (After)':>17} | {'Optimal T':>10}\")\n",
        "    print(\"-\" * 130)\n",
        "    for r in all_results:\n",
        "        print(f\"{r['name']:<22} | {r['acc']:>9.2f}% | {r['ece_before']:>12.4f}% | {r['ece_after']:>11.4f}% | {r['conf_before']:>17.2f}% | {r['conf_after']:>16.2f}% | {r['best_T']:>10.4f}\")\n",
        "    print(\"=\" * 130)\n",
        "else:\n",
        "    print(\"\\nNo models were successfully calibrated to display a final table.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A57vY_nG5mGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834eef41-67be-4d6e-8471-9ba5838395d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/cifar-10/ (stored 0%)\n",
            "  adding: content/cifar-10/ResNet-56_(Hub)_C10_ECE_vs_T.png (deflated 12%)\n",
            "  adding: content/cifar-10/ResNet-56_(Hub)_C10_reliability_before.png (deflated 12%)\n",
            "  adding: content/cifar-10/ResNet-164_C10_reliability_before.png (deflated 11%)\n",
            "  adding: content/cifar-10/ResNet-164_C10_ECE_vs_T.png (deflated 12%)\n",
            "  adding: content/cifar-10/ResNet-164_C10_reliability_after.png (deflated 12%)\n",
            "  adding: content/cifar-10/ResNet-56_(Hub)_C10_reliability_after.png (deflated 12%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/my_folder1.zip /content/cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Uk2hQLhPir4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3560066b-7d9c-497c-fad2-3257a446eea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/cifar-100/ (stored 0%)\n",
            "  adding: content/cifar-100/WideResNet-28-10_ECE_vs_T.png (deflated 11%)\n",
            "  adding: content/cifar-100/ResNet-56_(Hub)_reliability_after.png (deflated 11%)\n",
            "  adding: content/cifar-100/DenseNet-190_reliability_after.png (deflated 12%)\n",
            "  adding: content/cifar-100/ResNet-164_reliability_after.png (deflated 12%)\n",
            "  adding: content/cifar-100/ResNet-56_(Hub)_ECE_vs_T.png (deflated 9%)\n",
            "  adding: content/cifar-100/ResNet-164_reliability_before.png (deflated 12%)\n",
            "  adding: content/cifar-100/WideResNet-28-10_reliability_after.png (deflated 11%)\n",
            "  adding: content/cifar-100/ResNet-56_(Hub)_reliability_before.png (deflated 11%)\n",
            "  adding: content/cifar-100/DenseNet-190_ECE_vs_T.png (deflated 11%)\n",
            "  adding: content/cifar-100/WideResNet-28-10_reliability_before.png (deflated 11%)\n",
            "  adding: content/cifar-100/ResNet-164_ECE_vs_T.png (deflated 10%)\n",
            "  adding: content/cifar-100/DenseNet-190_reliability_before.png (deflated 12%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/my_folder2.zip /content/cifar-100/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pytorch-classification/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNsLNjcn6FuW",
        "outputId": "669f2c4b-f7aa-4c7e-fa42-e71235e6d66d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tlljB9DMlLNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PD00hJrilLIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYjOzkPbg8ov"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CARS-MOBILENETV2**"
      ],
      "metadata": {
        "id": "Fjhou4esiEB7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "sEMq9zUDg8mP",
        "outputId": "d816abb3-8ba4-407a-d95c-10f91f51fd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the kaggle.json file you downloaded from your Kaggle account.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d7a21d07-d29a-4097-b476-d783abdc9d58\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d7a21d07-d29a-4097-b476-d783abdc9d58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "\n",
            "Kaggle API token configured successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Please upload the kaggle.json file you downloaded from your Kaggle account.\")\n",
        "# This will open a file selection dialog\n",
        "files.upload()\n",
        "\n",
        "# Now, we'll move the file to the correct location and set permissions\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"\\nKaggle API token configured successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONr0kf-_jQC3",
        "outputId": "e61cb5d2-7862-4165-ba53-f4aa79af91e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jutrera/stanford-car-dataset-by-classes-folder\n",
            "License(s): other\n",
            "Downloading stanford-car-dataset-by-classes-folder.zip to /content/pytorch-classification\n",
            " 99% 1.80G/1.83G [00:23<00:00, 204MB/s]\n",
            "100% 1.83G/1.83G [00:23<00:00, 84.2MB/s]\n",
            "\n",
            "Dataset downloaded and unzipped successfully.\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d jutrera/stanford-car-dataset-by-classes-folder\n",
        "\n",
        "# # Unzip the downloaded file. The '-q' flag makes it quiet (less output).\n",
        "!unzip -q stanford-car-dataset-by-classes-folder.zip\n",
        "\n",
        "print(\"\\nDataset downloaded and unzipped successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk6fb4OVg8jc",
        "outputId": "2cc526b4-8623-427a-a6a8-28d93866c202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Using device: cuda\n",
            "\n",
            "Loading and splitting data...\n",
            "Found 196 classes in the dataset.\n",
            "Data successfully split:\n",
            "  -> Validation samples: 4000\n",
            "  -> Test samples:       4041\n",
            "\n",
            "Re-creating and loading MobileNetV2 model...\n",
            "Building model for 196 classes.\n",
            "Model loaded successfully.\n",
            "\n",
            "============================================================\n",
            " ECE Calibration for: MobileNetV2\n",
            "============================================================\n",
            "\n",
            "Test metrics BEFORE scaling (T=1.0)  Acc: 44.35%, Avg Conf: 53.77%, ECE: 9.421%\n",
            " Saved reliability diagram: /content/cars/MobileNetV2_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=1.00  ECE=9.759%\n",
            "T=1.04  ECE=8.005%\n",
            "T=1.08  ECE=6.334%\n",
            "T=1.12  ECE=4.670%\n",
            "T=1.17  ECE=3.102%\n",
            "T=1.21  ECE=2.386%\n",
            "T=1.25  ECE=2.494%\n",
            "T=1.29  ECE=2.498%\n",
            "T=1.33  ECE=3.828%\n",
            "T=1.38  ECE=5.068%\n",
            "T=1.42  ECE=6.419%\n",
            "T=1.46  ECE=7.592%\n",
            "T=1.50  ECE=8.840%\n",
            "T=1.54  ECE=10.017%\n",
            "T=1.58  ECE=11.120%\n",
            "T=1.62  ECE=12.290%\n",
            "T=1.67  ECE=13.319%\n",
            "T=1.71  ECE=14.378%\n",
            "T=1.75  ECE=15.419%\n",
            "T=1.79  ECE=16.422%\n",
            "T=1.83  ECE=17.398%\n",
            "T=1.88  ECE=18.341%\n",
            "T=1.92  ECE=19.235%\n",
            "T=1.96  ECE=20.068%\n",
            "T=2.00  ECE=20.894%\n",
            "\n",
            " Best T on Validation Set (Min ECE): 1.21  ECE=2.386%\n",
            " Saved ECE-vs-T curve: /content/cars/MobileNetV2_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=1.21)  Acc: 44.35%, Avg Conf: 45.50%, ECE: 2.200%\n",
            "\n",
            " Saved reliability diagram: /content/cars/MobileNetV2_reliability_after.png\n",
            "\n",
            "==================================================================================================================================\n",
            " Final Calibration Comparison on Stanford Cars Test Set\n",
            "==================================================================================================================================\n",
            "Model                  |   Accuracy |  ECE (Before) |  ECE (After) |  Avg Conf (Before) |  Avg Conf (After) |  Optimal T\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "MobileNetV2            |     44.35% |       9.4215% |      2.2003% |             53.77% |            45.50% |     1.2083\n",
            "==================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. SETUP & DATA LOADING (From your script)\n",
        "# ==============================================================================\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"==> Using device: {device}\")\n",
        "\n",
        "# --- Data Transforms ---\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "}\n",
        "\n",
        "# --- Load and Split Data ---\n",
        "print(\"\\nLoading and splitting data...\")\n",
        "try:\n",
        "    # 1. Load the original test set from ImageFolder\n",
        "    full_test_dataset = datasets.ImageFolder('/content/pytorch-classification/car_data/car_data/test', data_transforms['test'])\n",
        "\n",
        "    # --- FIX: Get num_classes from the ImageFolder *before* splitting ---\n",
        "    num_classes = len(full_test_dataset.classes)\n",
        "    print(f\"Found {num_classes} classes in the dataset.\")\n",
        "\n",
        "    # 2. Define split sizes\n",
        "    val_size = 4000\n",
        "    test_size = len(full_test_dataset) - val_size # Calculate remaining size\n",
        "\n",
        "    if test_size <= 0:\n",
        "        print(f\" ERROR: Validation size ({val_size}) is >= total test set ({len(full_test_dataset)}).\")\n",
        "        exit()\n",
        "\n",
        "    # 3. Split the dataset\n",
        "    val_dataset, test_dataset = random_split(full_test_dataset, [val_size, test_size],\n",
        "                                             generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    # 4. Create DataLoaders\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Data successfully split:\")\n",
        "    print(f\"  -> Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"  -> Test samples:       {len(test_dataset)}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\" ERROR: Data directory not found. Have you run the Kaggle download cell? {e}\")\n",
        "    # exit() # In a real script, you'd exit here\n",
        "except Exception as e:\n",
        "    print(f\" An error occurred during data loading: {e}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CALIBRATION & PLOTTING FUNCTIONS (From our CIFAR script)\n",
        "# ==============================================================================\n",
        "\n",
        "# Temperature grid\n",
        "T_values = np.linspace(1.0, 2.0, num=25)\n",
        "\n",
        "def get_predictions(model, loader, device, temp=1.0):\n",
        "    \"\"\"Gathers predictions, confidences, and labels.\"\"\"\n",
        "    model.eval()\n",
        "    all_confidences, all_correct = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Get logits from the base model\n",
        "            logits = model(inputs)\n",
        "\n",
        "            # Apply temperature\n",
        "            scaled_logits = logits / temp\n",
        "            probabilities = F.softmax(scaled_logits, dim=1)\n",
        "\n",
        "            confidences, predicted = torch.max(probabilities, 1)\n",
        "            correct = (predicted == labels).cpu().numpy()\n",
        "\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_correct.extend(correct)\n",
        "\n",
        "    return np.array(all_confidences), np.array(all_correct)\n",
        "\n",
        "def calculate_ece(confidences, correct, n_bins=15):\n",
        "    \"\"\"Calculates the Expected Calibration Error (ECE).\"\"\"\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    ece = 0.0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        prop_in_bin = np.mean(in_bin)\n",
        "        if prop_in_bin > 0:\n",
        "            accuracy_in_bin = np.mean(correct[in_bin])\n",
        "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
        "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "    return ece * 100\n",
        "\n",
        "def plot_reliability_diagram(confidences, correct, n_bins, model_name, suffix):\n",
        "    \"\"\"Plots a reliability diagram and saves it to a file.\"\"\"\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "\n",
        "    bin_accs = np.zeros(n_bins)\n",
        "    bin_confs = np.zeros(n_bins)\n",
        "    bin_props = np.zeros(n_bins)\n",
        "\n",
        "    for i, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        bin_props[i] = np.mean(in_bin)\n",
        "        if bin_props[i] > 0:\n",
        "            bin_accs[i] = np.mean(correct[in_bin])\n",
        "            bin_confs[i] = np.mean(confidences[in_bin])\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 7))\n",
        "    bar_width = 1.0 / n_bins\n",
        "    bar_centers = bin_lowers + bar_width / 2\n",
        "    non_empty_mask = bin_props > 0\n",
        "\n",
        "    # ECE bar plot\n",
        "    plt.bar(bar_centers[non_empty_mask], bin_accs[non_empty_mask],\n",
        "            width=bar_width * 0.9, alpha=0.3, color='red',\n",
        "            edgecolor='red', label='Accuracy')\n",
        "    # Gaps (where conf != acc)\n",
        "    plt.bar(bar_centers[non_empty_mask], (bin_confs - bin_accs)[non_empty_mask],\n",
        "            bottom=bin_accs[non_empty_mask],\n",
        "            width=bar_width * 0.9, alpha=0.5, color='blue',\n",
        "            edgecolor='black', label='Confidence Gap')\n",
        "\n",
        "    # Perfect calibration line\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "\n",
        "    plt.xlabel('Confidence')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Reliability Diagram: {model_name} ({suffix})')\n",
        "    plt.legend()\n",
        "    plt.xlim(0, 1)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    save_folder = \"/content/cars\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_reliability_{suffix}.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved reliability diagram: {filename}\")\n",
        "\n",
        "def plot_ece_vs_temp(T_values, ece_values, best_T, model_name):\n",
        "    \"\"\"Plots ECE vs. Temperature and saves it to a file.\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(T_values, ece_values, 'o-', label='ECE (%)', color='royalblue')\n",
        "    plt.axvline(best_T, color='red', linestyle='--',\n",
        "                label=f'Min ECE at T={best_T:.2f}')\n",
        "    plt.xlabel('Temperature (T)')\n",
        "    plt.ylabel('Expected Calibration Error (%)')\n",
        "    plt.title(f'ECE vs Temperature (Validation Set): {model_name}')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_folder = \"/content/cars\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_ECE_vs_T.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved ECE-vs-T curve: {filename}\")\n",
        "\n",
        "def run_ece_calibration(model, model_name, n_bins=15):\n",
        "    \"\"\"Runs the full grid-search calibration pipeline.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\" ECE Calibration for: {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # --- Test metrics BEFORE scaling ---\n",
        "    conf_b, corr_b = get_predictions(model, test_loader, device, temp=1.0)\n",
        "    ece_b = calculate_ece(conf_b, corr_b, n_bins=n_bins)\n",
        "    acc_b = np.mean(corr_b) * 100\n",
        "    avg_conf_b = np.mean(conf_b) * 100\n",
        "\n",
        "    print(f\"\\nTest metrics BEFORE scaling (T=1.0)  Acc: {acc_b:.2f}%, Avg Conf: {avg_conf_b:.2f}%, ECE: {ece_b:.3f}%\")\n",
        "    plot_reliability_diagram(conf_b, corr_b, n_bins, model_name, \"before\")\n",
        "\n",
        "    # --- Temperature search on validation set ---\n",
        "    best_ece_val = float('inf')\n",
        "    best_T = None\n",
        "    print(\"\\nValidation set temperature search:\")\n",
        "    ece_values_val = []\n",
        "    for T in T_values:\n",
        "        conf, corr = get_predictions(model, val_loader, device, temp=T)\n",
        "        ece = calculate_ece(conf, corr, n_bins=n_bins)\n",
        "        ece_values_val.append(ece)\n",
        "        print(f\"T={T:.2f}  ECE={ece:.3f}%\")\n",
        "        if ece < best_ece_val:\n",
        "            best_ece_val = ece\n",
        "            best_T = T\n",
        "\n",
        "    print(f\"\\n Best T on Validation Set (Min ECE): {best_T:.2f}  ECE={best_ece_val:.3f}%\")\n",
        "    plot_ece_vs_temp(T_values, ece_values_val, best_T, model_name)\n",
        "\n",
        "    # --- Test metrics AFTER scaling ---\n",
        "    conf_a, corr_a = get_predictions(model, test_loader, device, temp=best_T)\n",
        "    ece_a = calculate_ece(conf_a, corr_a, n_bins=n_bins)\n",
        "    acc_a = np.mean(corr_a) * 100\n",
        "    avg_conf_a = np.mean(conf_a) * 100\n",
        "\n",
        "    print(f\"\\nTest metrics AFTER scaling (T={best_T:.2f})  Acc: {acc_a:.2f}%, Avg Conf: {avg_conf_a:.2f}%, ECE: {ece_a:.3f}%\\n\")\n",
        "    plot_reliability_diagram(conf_a, corr_a, n_bins, model_name, \"after\")\n",
        "\n",
        "    # --- Return results for final table ---\n",
        "    return {\n",
        "        \"name\": model_name,\n",
        "        \"acc\": acc_a,\n",
        "        \"ece_before\": ece_b,\n",
        "        \"ece_after\": ece_a,\n",
        "        \"conf_before\": avg_conf_b,\n",
        "        \"conf_after\": avg_conf_a,\n",
        "        \"best_T\": best_T\n",
        "    }\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. LOAD MODEL AND RUN CALIBRATION\n",
        "# ==============================================================================\n",
        "all_results = []\n",
        "try:\n",
        "    print(\"\\nRe-creating and loading MobileNetV2 model...\")\n",
        "    base_model = models.mobilenet_v2(weights=None) # Using weights=None as you're loading a local state_dict\n",
        "\n",
        "    # --- FIX: Check if num_classes was defined in the data section ---\n",
        "    if 'num_classes' not in locals():\n",
        "        print(\" CRITICAL ERROR: num_classes was not defined. Cannot build model.\")\n",
        "        raise NameError(\"num_classes not defined\")\n",
        "\n",
        "    print(f\"Building model for {num_classes} classes.\")\n",
        "\n",
        "    in_features = base_model.classifier[1].in_features\n",
        "    base_model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "    base_model.to(device)\n",
        "\n",
        "    MODEL_PATH = '/content/Project/MobilenetV2_Cars/model_best.pth'\n",
        "    base_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "    print(\"Model loaded successfully.\")\n",
        "\n",
        "    # --- Run the full calibration pipeline ---\n",
        "    results = run_ece_calibration(base_model, \"MobileNetV2\")\n",
        "    all_results.append(results)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\" CRITICAL ERROR: Could not find model at '{MODEL_PATH}'\")\n",
        "except Exception as e:\n",
        "    print(f\" An error occurred: {e}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. FINAL REPORT \n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*130)\n",
        "print(\" Final Calibration Comparison on Stanford Cars Test Set\")\n",
        "print(\"=\"*130)\n",
        "\n",
        "# Print Header (FIXED typo V>)\n",
        "print(f\"{'Model':<22} | {'Accuracy':>10} | {'ECE (Before)':>13} | {'ECE (After)':>12} | {'Avg Conf (Before)':>18} | {'Avg Conf (After)':>17} | {'Optimal T':>10}\")\n",
        "print(\"-\" * 130)\n",
        "\n",
        "# Print results\n",
        "if all_results:\n",
        "    for r in all_results:\n",
        "        print(f\"{r['name']:<22} | {r['acc']:>9.2f}% | {r['ece_before']:>12.4f}% | {r['ece_after']:>11.4f}% | {r['conf_before']:>17.2f}% | {r['conf_after']:>16.2f}% | {r['best_T']:>10.4f}\")\n",
        "else:\n",
        "    print(\"No results to display. Model loading or calibration may have failed.\")\n",
        "print(\"=\" * 130)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L45ZL658g8gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e29ed69-e50d-42ba-bdd5-ad854ae61fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/cars/ (stored 0%)\n",
            "  adding: content/cars/MobileNetV2_ECE_vs_T.png (deflated 9%)\n",
            "  adding: content/cars/MobileNetV2_reliability_before.png (deflated 12%)\n",
            "  adding: content/cars/MobileNetV2_reliability_after.png (deflated 12%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/my_folder3.zip /content/cars/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c1ydtPzUWZi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMBIThFYBQhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Birds ~ InceptionV3**"
      ],
      "metadata": {
        "id": "CyBePJuck6oQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading birds400 dataset...\")\n",
        "!kaggle datasets download -d antoniozarauzmoreno/birds400\n",
        "\n",
        "# Unzip the file (q = quiet)\n",
        "print(\"Unzipping dataset...\")\n",
        "!unzip -q birds400.zip\n",
        "print(\"Dataset downloaded and unzipped successfully.\")\n",
        "\n",
        "# List contents to confirm\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cto4gK7su_8a",
        "outputId": "fefd96bd-9187-497d-fc98-d1e51fdb7c86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading birds400 dataset...\n",
            "Dataset URL: https://www.kaggle.com/datasets/antoniozarauzmoreno/birds400\n",
            "License(s): unknown\n",
            "Downloading birds400.zip to /content\n",
            " 98% 1.28G/1.30G [00:08<00:00, 293MB/s]\n",
            "100% 1.30G/1.30G [00:08<00:00, 161MB/s]\n",
            "Unzipping dataset...\n",
            "Dataset downloaded and unzipped successfully.\n",
            "total 1366148\n",
            "drwxr-xr-x  5 root root       4096 Oct 24 15:04 birds400\n",
            "-rw-r--r--  1 root root 1398909039 Apr 12  2022 birds400.zip\n",
            "drwx------  5 root root       4096 Oct 24 14:53 drive\n",
            "-rw-r--r--  1 root root         65 Oct 24 15:03 kaggle.json\n",
            "drwxr-xr-x 11 root root       4096 Oct 24 14:44 Project\n",
            "drwxr-xr-x  1 root root       4096 Oct 22 13:39 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. SETUP & DATA LOADING\n",
        "# ==============================================================================\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"==> Using device: {device}\")\n",
        "\n",
        "# --- Data Transforms ---\n",
        "data_transforms = {\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(299),\n",
        "        transforms.CenterCrop(299),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "}\n",
        "\n",
        "# --- Load and Split Data ---\n",
        "print(\"\\nLoading and splitting data...\")\n",
        "BIRDS_TEST_PATH = '/content/birds400/test'\n",
        "\n",
        "try:\n",
        "    full_test_dataset = datasets.ImageFolder(BIRDS_TEST_PATH, data_transforms['test'])\n",
        "    num_classes = len(full_test_dataset.classes)\n",
        "    print(f\"Found {num_classes} classes in the dataset.\")\n",
        "\n",
        "    val_size = 1000\n",
        "    if len(full_test_dataset) <= val_size:\n",
        "        print(f\" ERROR: Total test set ({len(full_test_dataset)}) is too small for validation size ({val_size}).\")\n",
        "        exit()\n",
        "    test_size = len(full_test_dataset) - val_size\n",
        "\n",
        "    val_dataset, test_dataset = random_split(full_test_dataset, [val_size, test_size],\n",
        "                                             generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Data successfully split:\")\n",
        "    print(f\"  -> Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"  -> Test samples:       {len(test_dataset)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\" ERROR: Data directory not found at: {BIRDS_TEST_PATH}\")\n",
        "    print(\"Please make sure you ran the data preparation cell first.\")\n",
        "except Exception as e:\n",
        "    print(f\" An error occurred during data loading: {e}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CALIBRATION & PLOTTING FUNCTIONS\n",
        "# ==============================================================================\n",
        "T_values = np.linspace(0.5, 1.5, num=25)\n",
        "\n",
        "def get_predictions(model, loader, device, temp=1.0):\n",
        "    model.eval()\n",
        "    all_confidences, all_correct = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            logits = model(inputs)\n",
        "            if isinstance(logits, tuple): # Handle InceptionV3 tuple output\n",
        "                logits = logits.logits\n",
        "            scaled_logits = logits / temp\n",
        "            probabilities = F.softmax(scaled_logits, dim=1)\n",
        "            confidences, predicted = torch.max(probabilities, 1)\n",
        "            correct = (predicted == labels).cpu().numpy()\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_correct.extend(correct)\n",
        "    return np.array(all_confidences), np.array(all_correct)\n",
        "\n",
        "def calculate_ece(confidences, correct, n_bins=15):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    ece = 0.0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        prop_in_bin = np.mean(in_bin)\n",
        "        if prop_in_bin > 0:\n",
        "            accuracy_in_bin = np.mean(correct[in_bin])\n",
        "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
        "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "    return ece * 100\n",
        "\n",
        "def plot_reliability_diagram(confidences, correct, n_bins, model_name, suffix):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    bin_accs, bin_confs, bin_props = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
        "    for i, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        bin_props[i] = np.mean(in_bin)\n",
        "        if bin_props[i] > 0:\n",
        "            bin_accs[i] = np.mean(correct[in_bin])\n",
        "            bin_confs[i] = np.mean(confidences[in_bin])\n",
        "    plt.figure(figsize=(8, 7))\n",
        "    bar_width = 1.0 / n_bins\n",
        "    bar_centers = bin_lowers + bar_width / 2\n",
        "    non_empty_mask = bin_props > 0\n",
        "    plt.bar(bar_centers[non_empty_mask], bin_accs[non_empty_mask], width=bar_width*0.9, alpha=0.3, color='red', edgecolor='red', label='Accuracy')\n",
        "    plt.bar(bar_centers[non_empty_mask], (bin_confs - bin_accs)[non_empty_mask], bottom=bin_accs[non_empty_mask], width=bar_width*0.9, alpha=0.5, color='blue', edgecolor='black', label='Confidence Gap')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "    plt.xlabel('Confidence'); plt.ylabel('Accuracy'); plt.title(f'Reliability Diagram: {model_name} ({suffix})')\n",
        "    plt.legend(); plt.xlim(0, 1); plt.ylim(0, 1); plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_folder = \"/content/birds\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_reliability_{suffix}.png\"\n",
        "    plt.savefig(filename); plt.close()\n",
        "    print(f\" Saved reliability diagram: {filename}\")\n",
        "\n",
        "def plot_ece_vs_temp(T_values, ece_values, best_T, model_name):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(T_values, ece_values, 'o-', label='ECE (%)', color='royalblue')\n",
        "    plt.axvline(best_T, color='red', linestyle='--', label=f'Min ECE at T={best_T:.2f}')\n",
        "    plt.xlabel('Temperature (T)'); plt.ylabel('Expected Calibration Error (%)'); plt.title(f'ECE vs Temperature (Validation Set): {model_name}')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6); plt.legend(); plt.tight_layout()\n",
        "    save_folder = \"/content/birds\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_ECE_vs_T.png\"\n",
        "    plt.savefig(filename); plt.close()\n",
        "    print(f\" Saved ECE-vs-T curve: {filename}\")\n",
        "\n",
        "def run_ece_calibration(model, model_name, n_bins=15):\n",
        "    print(\"\\n\" + \"=\"*60); print(f\" ECE Calibration for: {model_name}\"); print(\"=\"*60)\n",
        "    model.to(device).eval()\n",
        "    conf_b, corr_b = get_predictions(model, test_loader, device, temp=1.0)\n",
        "    ece_b = calculate_ece(conf_b, corr_b, n_bins=n_bins)\n",
        "    acc_b = np.mean(corr_b) * 100\n",
        "    avg_conf_b = np.mean(conf_b) * 100\n",
        "    print(f\"\\nTest metrics BEFORE scaling (T=1.0)  Acc: {acc_b:.2f}%, Avg Conf: {avg_conf_b:.2f}%, ECE: {ece_b:.3f}%\")\n",
        "    plot_reliability_diagram(conf_b, corr_b, n_bins, model_name, \"before\")\n",
        "    best_ece_val, best_T, ece_values_val = float('inf'), None, []\n",
        "    print(\"\\nValidation set temperature search:\")\n",
        "    for T in T_values:\n",
        "        conf, corr = get_predictions(model, val_loader, device, temp=T)\n",
        "        ece = calculate_ece(conf, corr, n_bins=n_bins)\n",
        "        ece_values_val.append(ece)\n",
        "        print(f\"T={T:.2f}  ECE={ece:.3f}%\")\n",
        "        if ece < best_ece_val:\n",
        "            best_ece_val, best_T = ece, T\n",
        "    print(f\"\\n Best T on Validation Set (Min ECE): {best_T:.2f}  ECE={best_ece_val:.3f}%\")\n",
        "    plot_ece_vs_temp(T_values, ece_values_val, best_T, model_name)\n",
        "    conf_a, corr_a = get_predictions(model, test_loader, device, temp=best_T)\n",
        "    ece_a = calculate_ece(conf_a, corr_a, n_bins=n_bins)\n",
        "    acc_a = np.mean(corr_a) * 100\n",
        "    avg_conf_a = np.mean(conf_a) * 100\n",
        "    print(f\"\\nTest metrics AFTER scaling (T={best_T:.2f})  Acc: {acc_a:.2f}%, Avg Conf: {avg_conf_a:.2f}%, ECE: {ece_a:.3f}%\\n\")\n",
        "    plot_reliability_diagram(conf_a, corr_a, n_bins, model_name, \"after\")\n",
        "    return {\"name\": model_name, \"acc\": acc_a, \"ece_before\": ece_b, \"ece_after\": ece_a,\n",
        "            \"conf_before\": avg_conf_b, \"conf_after\": avg_conf_a, \"best_T\": best_T}\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. LOAD MODEL AND RUN CALIBRATION (FIXED LOADING)\n",
        "# ==============================================================================\n",
        "all_results = []\n",
        "try:\n",
        "    if 'num_classes' not in locals():\n",
        "        print(\" CRITICAL ERROR: num_classes was not defined. Data loading likely failed.\")\n",
        "        raise NameError(\"num_classes not defined\")\n",
        "\n",
        "    model_name = \"InceptionV3_Fold9\"\n",
        "    MODEL_PATH = \"/content/Project/InceptionNetV3_Birds/inceptionv3_birds9.pth\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80); print(f\"STARTING CALIBRATION FOR: {model_name} from {MODEL_PATH}\"); print(\"=\"*80)\n",
        "\n",
        "    # 1. Load the object from the .pth file\n",
        "    import torchvision\n",
        "    torch.serialization.add_safe_globals([torchvision.models.inception.Inception3])\n",
        "    loaded_object = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "    # --- FIX: Check if loaded object is the model or a state dict ---\n",
        "    if isinstance(loaded_object, nn.Module):\n",
        "        print(\"Loaded object is a full model instance.\")\n",
        "        base_model = loaded_object\n",
        "        # Ensure the final layer matches the dataset\n",
        "        in_features = base_model.fc.in_features\n",
        "        if base_model.fc.out_features != num_classes:\n",
        "             print(f\"Warning: Model's final layer ({base_model.fc.out_features} classes) doesn't match dataset ({num_classes} classes). Rebuilding final layer.\")\n",
        "             base_model.fc = nn.Linear(in_features, num_classes)\n",
        "        base_model.to(device)\n",
        "    elif isinstance(loaded_object, dict):\n",
        "        print(\"Loaded object is a state dictionary or checkpoint.\")\n",
        "        # Create a new InceptionV3 instance first\n",
        "        base_model = models.inception_v3(weights=None, aux_logits=False, init_weights=False)\n",
        "        in_features = base_model.fc.in_features\n",
        "        base_model.fc = nn.Linear(in_features, num_classes)\n",
        "        base_model.to(device)\n",
        "\n",
        "        # Extract state_dict if it's a checkpoint dict\n",
        "        if 'state_dict' in loaded_object:\n",
        "            state_dict = loaded_object['state_dict']\n",
        "        else:\n",
        "            state_dict = loaded_object # Assume it's just the state_dict\n",
        "\n",
        "        # Handle potential 'module.' prefix from DataParallel\n",
        "        new_sd = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            new_sd[k.replace('module.', '')] = v\n",
        "\n",
        "        base_model.load_state_dict(new_sd)\n",
        "    else:\n",
        "        raise TypeError(f\"Loaded object is of unexpected type: {type(loaded_object)}\")\n",
        "\n",
        "    print(\"Model prepared successfully.\")\n",
        "\n",
        "    # 4. Run the full calibration pipeline\n",
        "    results = run_ece_calibration(base_model, model_name)\n",
        "    all_results.append(results)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\" CRITICAL ERROR: Could not find weights at '{MODEL_PATH}'\")\n",
        "except Exception as e:\n",
        "    print(f\" An error occurred during model loading or calibration: {e}\")\n",
        "    print(\"This could be a model/dataset class mismatch or a loading issue.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. FINAL REPORT  (FIXED TYPO)\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*130)\n",
        "print(\" Final Calibration Comparison on Birds Dataset Test Set\")\n",
        "print(\"=\"*130)\n",
        "\n",
        "# --- FIX: Corrected format specifier ---\n",
        "print(f\"{'Model':<22} | {'Accuracy':>10} | {'ECE (Before)':>13} | {'ECE (After)':>12} | {'Avg Conf (Before)':>18} | {'Avg Conf (After)':>17} | {'Optimal T':>10}\")\n",
        "print(\"-\" * 130)\n",
        "\n",
        "# Print results\n",
        "if all_results:\n",
        "    for r in all_results:\n",
        "        print(f\"{r['name']:<22} | {r['acc']:>9.2f}% | {r['ece_before']:>12.4f}% | {r['ece_after']:>11.4f}% | {r['conf_before']:>17.2f}% | {r['conf_after']:>16.2f}% | {r['best_T']:>10.4f}\")\n",
        "else:\n",
        "    print(\"No results to display. Model loading or calibration may have failed.\")\n",
        "print(\"=\" * 130)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnP2n6vylA26",
        "outputId": "da23e356-f823-465b-9688-b04d3d739169"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Using device: cuda\n",
            "\n",
            "Loading and splitting data...\n",
            "Found 400 classes in the dataset.\n",
            "Data successfully split:\n",
            "  -> Validation samples: 1000\n",
            "  -> Test samples:       1000\n",
            "\n",
            "================================================================================\n",
            "STARTING CALIBRATION FOR: InceptionV3_Fold9 from /content/Project/InceptionNetV3_Birds/inceptionv3_birds9.pth\n",
            "================================================================================\n",
            "Loaded object is a full model instance.\n",
            "Model prepared successfully.\n",
            "\n",
            "============================================================\n",
            " ECE Calibration for: InceptionV3_Fold9\n",
            "============================================================\n",
            "\n",
            "Test metrics BEFORE scaling (T=1.0)  Acc: 98.90%, Avg Conf: 98.65%, ECE: 0.503%\n",
            " Saved reliability diagram: /content/birds/InceptionV3_Fold9_reliability_before.png\n",
            "\n",
            "Validation set temperature search:\n",
            "T=0.50  ECE=0.318%\n",
            "T=0.54  ECE=0.317%\n",
            "T=0.58  ECE=0.358%\n",
            "T=0.62  ECE=0.362%\n",
            "T=0.67  ECE=0.391%\n",
            "T=0.71  ECE=0.312%\n",
            "T=0.75  ECE=0.325%\n",
            "T=0.79  ECE=0.344%\n",
            "T=0.83  ECE=0.376%\n",
            "T=0.88  ECE=0.443%\n",
            "T=0.92  ECE=0.473%\n",
            "T=0.96  ECE=0.618%\n",
            "T=1.00  ECE=0.690%\n",
            "T=1.04  ECE=0.829%\n",
            "T=1.08  ECE=0.996%\n",
            "T=1.12  ECE=1.197%\n",
            "T=1.17  ECE=1.437%\n",
            "T=1.21  ECE=1.722%\n",
            "T=1.25  ECE=2.061%\n",
            "T=1.29  ECE=2.461%\n",
            "T=1.33  ECE=2.928%\n",
            "T=1.38  ECE=3.472%\n",
            "T=1.42  ECE=4.099%\n",
            "T=1.46  ECE=4.818%\n",
            "T=1.50  ECE=5.634%\n",
            "\n",
            " Best T on Validation Set (Min ECE): 0.71  ECE=0.312%\n",
            " Saved ECE-vs-T curve: /content/birds/InceptionV3_Fold9_ECE_vs_T.png\n",
            "\n",
            "Test metrics AFTER scaling (T=0.71)  Acc: 98.90%, Avg Conf: 99.29%, ECE: 0.849%\n",
            "\n",
            " Saved reliability diagram: /content/birds/InceptionV3_Fold9_reliability_after.png\n",
            "\n",
            "==================================================================================================================================\n",
            " Final Calibration Comparison on Birds Dataset Test Set\n",
            "==================================================================================================================================\n",
            "Model                  |   Accuracy |  ECE (Before) |  ECE (After) |  Avg Conf (Before) |  Avg Conf (After) |  Optimal T\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "InceptionV3_Fold9      |     98.90% |       0.5027% |      0.8494% |             98.65% |            99.29% |     0.7083\n",
            "==================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/birds_inceptionV3 .zip /content/birds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNDrE0A91ctQ",
        "outputId": "e5c6e16a-5b93-4fac-b0c3-0b86895e6bb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: .zip\n",
            "  adding: content/birds/ (stored 0%)\n",
            "  adding: content/birds/InceptionV3_Fold9_reliability_after.png (deflated 11%)\n",
            "  adding: content/birds/InceptionV3_Fold9_reliability_before.png (deflated 11%)\n",
            "  adding: content/birds/InceptionV3_Fold9_ECE_vs_T.png (deflated 11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why ECE Increased After Scaling\n",
        "\n",
        "The ECE increased because the **optimal temperature (T)** found on the validation set was **less than 1** (T=0.71).\n",
        "\n",
        "---\n",
        "\n",
        "### Understanding Temperature Scaling\n",
        "\n",
        "* **Standard Case (T > 1):** Most models are *over-confident*. Temperature Scaling divides the logits by $T > 1$, which \"cools down\" the probabilities, making the model *less confident* and usually reducing ECE.\n",
        "* **Our Case (T < 1):** Dividing logits by $T < 1$ actually **increases** the differences between logits. This \"sharpens\" the probabilities, making the model *more confident*.\n",
        "\n",
        "This increase in confidence is visible in the results:\n",
        "* **Avg Conf (Before):** 98.65%\n",
        "* **Avg Conf (After):** 99.29% \n",
        "\n",
        "---\n",
        "\n",
        "### Why the Validation Set Suggested T < 1\n",
        "\n",
        "Our original model was **already exceptionally well-calibrated**, perhaps even slightly *under-confident* on the validation set data.\n",
        "\n",
        "* **Before Scaling (Validation, T=1.0):** ECE = 0.690%\n",
        "* **Best T (Validation, T=0.71):** ECE decreased slightly to 0.312%\n",
        "\n",
        "The grid search found that making the model slightly *more* confident (by using $T < 1$) achieved the absolute minimum ECE *specifically on that validation dataset*.\n",
        "\n",
        "---\n",
        "\n",
        "### Why ECE Increased on the Test Set\n",
        "\n",
        "The minor improvement seen on the validation set by using $T=0.71$ **didn't generalize** perfectly to the separate test set.\n",
        "\n",
        "* **Before Scaling (Test, T=1.0):** ECE was extremely low at **0.503%**. The confidence (98.65%) was very close to the accuracy (98.90%).\n",
        "* **After Scaling (Test, T=0.71):** Applying $T=0.71$ made the model slightly *over-confident* on the test set (Avg Conf 99.29% > Accuracy 98.90%). This resulted in a small increase in the final test ECE to **0.849%**.\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusion \n",
        "\n",
        "Our original model was already remarkably well-calibrated (ECE  0.5%). Temperature scaling tried a minor adjustment based on the validation set (making the model slightly more confident), but this wasn't beneficial for the test set.\n",
        "\n",
        "In this rare situation, the **unscaled model (T=1.0) actually had slightly better calibration** on the final test data. An ECE difference this small (0.5% vs 0.85%) is often considered negligible in practice. "
      ],
      "metadata": {
        "id": "xisIM__30Cbi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zwk9KiBwd2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l72tWT4IwdxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_kIe5hIwduQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LLxFqPqwdiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extra Work : Trying to see performance of label smoothing**"
      ],
      "metadata": {
        "id": "sn55tpM7BRXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# ECE CALIBRATION via LABEL SMOOTHING (LS) FINE-TUNING\n",
        "# -----------------------------\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Data Transforms ---\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "# --- Load and Split Data (NEW: Need Training Set) ---\n",
        "print(\"\\nLoading CIFAR-10 data for fine-tuning...\")\n",
        "try:\n",
        "    # 1. Load the 50,000-image training set\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    # 2. Load the 10,000-image test set for final evaluation\n",
        "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Data loaded:\")\n",
        "    print(f\"  -> Training samples: {len(train_dataset)}\")\n",
        "    print(f\"  -> Test samples:     {len(test_dataset)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" ERROR: Could not load CIFAR-10 data. {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Helper Functions (Re-used) ---\n",
        "\n",
        "def get_predictions(model, loader, device, temp=1.0):\n",
        "    model.eval()\n",
        "    all_conf, all_corr = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x) / temp\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            conf, pred = torch.max(probs, 1)\n",
        "            all_conf.extend(conf.cpu().numpy())\n",
        "            all_corr.extend((pred == y).cpu().numpy())\n",
        "    return np.array(all_conf), np.array(all_corr)\n",
        "\n",
        "def calculate_ece(confidences, correct, n_bins=15):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    ece = 0.0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        prop_in_bin = np.mean(in_bin)\n",
        "        if prop_in_bin > 0:\n",
        "            accuracy_in_bin = np.mean(correct[in_bin])\n",
        "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
        "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "    return ece * 100\n",
        "\n",
        "def plot_reliability_diagram(confidences, correct, n_bins, model_name, suffix):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    bin_accs, bin_confs, bin_props = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
        "\n",
        "    for i, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        bin_props[i] = np.mean(in_bin)\n",
        "        if bin_props[i] > 0:\n",
        "            bin_accs[i] = np.mean(correct[in_bin])\n",
        "            bin_confs[i] = np.mean(confidences[in_bin])\n",
        "\n",
        "    plt.figure(figsize=(8, 7))\n",
        "    bar_width, bar_centers = 1.0 / n_bins, bin_lowers + 1.0 / (2 * n_bins)\n",
        "    non_empty = bin_props > 0\n",
        "    plt.bar(bar_centers[non_empty], bin_accs[non_empty], width=bar_width*0.9, alpha=0.3, color='red', edgecolor='red', label='Accuracy')\n",
        "    plt.bar(bar_centers[non_empty], (bin_confs - bin_accs)[non_empty], bottom=bin_accs[non_empty], width=bar_width*0.9, alpha=0.5, color='blue', edgecolor='black', label='Confidence Gap')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "    plt.xlabel('Confidence'); plt.ylabel('Accuracy'); plt.title(f'Reliability Diagram: {model_name} ({suffix})')\n",
        "    plt.legend(); plt.xlim(0, 1); plt.ylim(0, 1); plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Save to a new folder\n",
        "    save_folder = \"/content/cifar-10-ls\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_C10_reliability_{suffix}.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved reliability diagram: {filename}\")\n",
        "\n",
        "def load_checkpoint(model, path, device):\n",
        "    print(f\"Loading checkpoint: {path}\")\n",
        "    ckpt = torch.load(path, map_location=device, weights_only=False)\n",
        "    state_dict = ckpt.get('state_dict', ckpt)\n",
        "    new_sd = OrderedDict((k.replace('module.', ''), v) for k, v in state_dict.items())\n",
        "    model.load_state_dict(new_sd)\n",
        "    return model\n",
        "\n",
        "# --- NEW: Fine-Tuning Function ---\n",
        "def finetune_with_ls(model, loader, epochs=10, lr=1e-5, smoothing=0.1):\n",
        "    print(f\"\\n--- Starting fine-tuning with Label Smoothing (={smoothing}) for {epochs} epochs ---\")\n",
        "    model.to(device).train()\n",
        "\n",
        "    # Define loss function with label smoothing\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
        "\n",
        "    # Use an optimizer with a very small learning rate for fine-tuning\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss / len(loader):.4f}\")\n",
        "\n",
        "    print(\"--- Fine-tuning complete ---\")\n",
        "    return model\n",
        "\n",
        "# --- NEW: Evaluation Function for LS-Tuned Models ---\n",
        "def evaluate_ls_model(model, model_name, n_bins=15):\n",
        "    print(f\"\\n--- Evaluating LS fine-tuned model: {model_name} ---\")\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # Evaluate with T=1.0 (no post-hoc scaling)\n",
        "    conf, corr = get_predictions(model, test_loader, device, temp=1.0)\n",
        "    ece = calculate_ece(conf, corr, n_bins=n_bins)\n",
        "    acc = np.mean(corr) * 100\n",
        "    avg_conf = np.mean(conf) * 100\n",
        "\n",
        "    print(f\"Test metrics  Acc: {acc:.2f}%, Avg Conf: {avg_conf:.2f}%, ECE: {ece:.3f}%\")\n",
        "\n",
        "    # Plot reliability diagram, save with \"ls\" suffix\n",
        "    plot_reliability_diagram(conf, corr, n_bins, model_name, \"ls\")\n",
        "\n",
        "    return {\"name\": model_name, \"acc\": acc, \"ece_ls\": ece, \"conf_ls\": avg_conf}\n",
        "\n",
        "\n",
        "# =======================================================\n",
        "# --- RUN FINE-TUNING & EVALUATION FOR LS MODELS ---\n",
        "# =======================================================\n",
        "all_ls_results = []\n",
        "\n",
        "# --- 1. ResNet-164 ---\n",
        "try:\n",
        "    from models.cifar import resnet\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Running LS fine-tuning for local ResNet-164\")\n",
        "    print(\"=\"*60)\n",
        "    model_resnet164 = resnet(depth=164, num_classes=10, block_name='Bottleneck')\n",
        "    path = '/content/Project/resnet110cifar10/model_best.pth.tar'\n",
        "    model_resnet164 = load_checkpoint(model_resnet164, path, device)\n",
        "\n",
        "    # Fine-tune the model\n",
        "    model_resnet164_ls = finetune_with_ls(model_resnet164, train_loader, epochs=10)\n",
        "\n",
        "    # Evaluate the fine-tuned model\n",
        "    results = evaluate_ls_model(model_resnet164_ls, \"ResNet-164 (LS Tuned)\")\n",
        "    all_ls_results.append(results)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Skipping local ResNet-164: {e}\")\n",
        "\n",
        "# --- 2. ResNet-56 from torch.hub ---\n",
        "try:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Running LS fine-tuning for ResNet-56 (torch.hub)\")\n",
        "    print(\"=\"*60)\n",
        "    # Load a fresh copy\n",
        "    model_hub = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet56\", pretrained=True, trust_repo=True)\n",
        "\n",
        "    # Fine-tune the model\n",
        "    model_hub_ls = finetune_with_ls(model_hub, train_loader, epochs=10)\n",
        "\n",
        "    # Evaluate the fine-tuned model\n",
        "    results = evaluate_ls_model(model_hub_ls, \"ResNet-56 (Hub, LS Tuned)\")\n",
        "    all_ls_results.append(results)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Skipping ResNet-56 (Hub): {e}\")\n",
        "\n",
        "# --- FINAL COMPARISON TABLE (for LS Models) ---\n",
        "if all_ls_results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" Final Results for Label Smoothing (LS) Fine-Tuning\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"{'Model':<28} | {'Accuracy':>10} | {'ECE (LS Tuned)':>15} | {'Avg Conf (LS)':>15}\")\n",
        "    print(\"-\" * 80)\n",
        "    for r in all_ls_results:\n",
        "        print(f\"{r['name']:<28} | {r['acc']:>9.2f}% | {r['ece_ls']:>14.4f}% | {r['conf_ls']:>14.2f}%\")\n",
        "    print(\"=\" * 80)\n",
        "else:\n",
        "    print(\"\\nNo models were successfully fine-tuned with Label Smoothing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBEp3T9o4g_i",
        "outputId": "63a4ea64-3eec-49ce-8e46-29e741c1a446"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Loading CIFAR-10 data for fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:13<00:00, 12.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded:\n",
            "  -> Training samples: 50000\n",
            "  -> Test samples:     10000\n",
            "\n",
            "============================================================\n",
            "Running LS fine-tuning for local ResNet-164\n",
            "============================================================\n",
            "Loading checkpoint: /content/Project/resnet110cifar10/model_best.pth.tar\n",
            "\n",
            "--- Starting fine-tuning with Label Smoothing (=0.1) for 10 epochs ---\n",
            "Epoch 1/10 | Loss: 1.2979\n",
            "Epoch 2/10 | Loss: 1.0464\n",
            "Epoch 3/10 | Loss: 0.9343\n",
            "Epoch 4/10 | Loss: 0.8599\n",
            "Epoch 5/10 | Loss: 0.8070\n",
            "Epoch 6/10 | Loss: 0.7665\n",
            "Epoch 7/10 | Loss: 0.7369\n",
            "Epoch 8/10 | Loss: 0.7138\n",
            "Epoch 9/10 | Loss: 0.6960\n",
            "Epoch 10/10 | Loss: 0.6839\n",
            "--- Fine-tuning complete ---\n",
            "\n",
            "--- Evaluating LS fine-tuned model: ResNet-164 (LS Tuned) ---\n",
            "Test metrics  Acc: 91.40%, Avg Conf: 85.75%, ECE: 5.649%\n",
            " Saved reliability diagram: /content/cifar-10-ls/ResNet-164_(LS_Tuned)_C10_reliability_ls.png\n",
            "\n",
            "============================================================\n",
            "Running LS fine-tuning for ResNet-56 (torch.hub)\n",
            "============================================================\n",
            "\n",
            "--- Starting fine-tuning with Label Smoothing (=0.1) for 10 epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6700\n",
            "Epoch 2/10 | Loss: 0.5498\n",
            "Epoch 3/10 | Loss: 0.5356\n",
            "Epoch 4/10 | Loss: 0.5279\n",
            "Epoch 5/10 | Loss: 0.5243\n",
            "Epoch 6/10 | Loss: 0.5216\n",
            "Epoch 7/10 | Loss: 0.5194\n",
            "Epoch 8/10 | Loss: 0.5182\n",
            "Epoch 9/10 | Loss: 0.5167\n",
            "Epoch 10/10 | Loss: 0.5157\n",
            "--- Fine-tuning complete ---\n",
            "\n",
            "--- Evaluating LS fine-tuned model: ResNet-56 (Hub, LS Tuned) ---\n",
            "Test metrics  Acc: 94.29%, Avg Conf: 89.55%, ECE: 4.825%\n",
            " Saved reliability diagram: /content/cifar-10-ls/ResNet-56_(Hub,_LS_Tuned)_C10_reliability_ls.png\n",
            "\n",
            "================================================================================\n",
            " Final Results for Label Smoothing (LS) Fine-Tuning\n",
            "================================================================================\n",
            "Model                        |   Accuracy |  ECE (LS Tuned) |   Avg Conf (LS)\n",
            "--------------------------------------------------------------------------------\n",
            "ResNet-164 (LS Tuned)        |     91.40% |         5.6494% |          85.75%\n",
            "ResNet-56 (Hub, LS Tuned)    |     94.29% |         4.8248% |          89.55%\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/cifar-10-ls.zip /content/cifar-10-ls/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjfQARIHBolM",
        "outputId": "6fdf2ab0-a1db-4dd2-8307-00183c666b8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/cifar-10-ls/ (stored 0%)\n",
            "  adding: content/cifar-10-ls/ResNet-56_(Hub,_LS_Tuned)_C10_reliability_ls.png (deflated 12%)\n",
            "  adding: content/cifar-10-ls/ResNet-164_(LS_Tuned)_C10_reliability_ls.png (deflated 11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an excellent (and common) result! We've stumbled upon a core finding in calibration research.\n",
        "\n",
        "Heres the direct answer: Our fine-tuning process damaged our model's performance, which in turn destroyed its calibration.\n",
        "\n",
        "The \"normal\" model's ECE was low (3.75%) because it was highly accurate (93.20%). Our new \"LS-Tuned\" model's ECE is high (5.65%) because it is less accurate (91.40%).\n",
        "\n",
        "Let's break down why this happened.\n",
        "\n",
        "## 1. The \"Smoking Gun\": Accuracy Drop\n",
        "\n",
        "Look at the accuracy for our ResNet-164:\n",
        "\n",
        "* **Before (Original Model):** 93.20%\n",
        "* **After (LS Fine-tune):** 91.40%\n",
        "\n",
        "We lost almost **2% accuracy**. This is a massive red flag. \n",
        "\n",
        "Our fine-tuning process (10 epochs with a new loss function) partially \"broke\" the model's highly optimized weights. Since ECE measures the gap between accuracy and confidence, a large drop in accuracy will almost always increase ECE, as the model's confidences no longer match its (new, lower) correctness.\n",
        "\n",
        "## 2. A \"Cure\" (TS) vs. A \"Prevention\" (LS)\n",
        "\n",
        "We are comparing two fundamentally different methods:\n",
        "\n",
        "* **Temperature Scaling (TS):** This is a *post-hoc* or *curative* method. It takes our finished, static, high-performing model (93.20% acc) and finds the mathematically optimal temperature to make its confidences match its accuracy. It is **non-destructive**it *cannot* hurt the model's accuracy.\n",
        "\n",
        "* **Label Smoothing (LS):** This is an *in-training* or *preventative* method. It's designed to be used *from scratch* (or for the entire training process) to *prevent* the model from becoming over-confident in the first place.\n",
        "\n",
        "We used LS as a fine-tuning method, which is an ad-hoc, **destructive** process (i.e., it changes the model's weights). This is risky, and in our case, it damaged the model's performance.\n",
        "\n",
        "## 3. Why the Fine-Tuning Failed\n",
        "\n",
        "The goal of our original model was to get the highest possible accuracy on the clean test set. It achieved 93.20%.\n",
        "\n",
        "The goal of our 10-epoch fine-Tuning was to minimize a *new* loss (Label-Smoothed Cross-Entropy) on the *augmented* training set (`RandomCrop`, `RandomFlip`).\n",
        "\n",
        "This new, short training process:\n",
        "\n",
        "* **Hurt Generalization:** It made the model slightly better at the augmented training data but *worse* at the clean test data (hence the accuracy drop).\n",
        "\n",
        "* **Didn't Run Long Enough:** 10 epochs isn't enough to properly re-settle the model. The model is now in a sub-optimal, \"confused\" stateless accurate than before, but (due to LS) also less confident. This new combination is *less* calibrated than the original.\n",
        "\n",
        "## The Key Takeaway \n",
        "\n",
        "This is actually a fantastic result! We've successfully demonstrated *why* Temperature Scaling is so effective and popular.\n",
        "\n",
        "* Our \"before\" model was already great: high accuracy (93.20%) and decent ECE (3.75%).\n",
        "* Our Temperature Scaling experiment took that great model and made it *nearly perfect* by reducing the ECE to **0.95%** with **zero risk** and no re-training.\n",
        "* Our Label Smoothing experiment tried to \"fix\" the model by re-training and *made it worse* (91.40% acc, 5.65% ECE).\n",
        "\n",
        "This shows that for a pre-trained model, a simple, non-destructive, post-hoc method like Temperature Scaling is almost always the superior, safer, and faster choice."
      ],
      "metadata": {
        "id": "LOvZa66bBY9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# TRAINING ResNet-164 w/ LABEL SMOOTHING (LS)\n",
        "# -----------------------------\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Data Transforms ---\n",
        "print(\"Loading CIFAR-10 data...\")\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "# --- Data Loaders ---\n",
        "try:\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "    print(f\"Data loaded: {len(train_dataset)} train, {len(test_dataset)} test samples.\")\n",
        "except Exception as e:\n",
        "    print(f\" ERROR: Could not load CIFAR-10 data. {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Helper Functions (Evaluation) ---\n",
        "def get_predictions(model, loader, device, temp=1.0):\n",
        "    model.eval()\n",
        "    all_conf, all_corr = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x) / temp\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            conf, pred = torch.max(probs, 1)\n",
        "            all_conf.extend(conf.cpu().numpy())\n",
        "            all_corr.extend((pred == y).cpu().numpy())\n",
        "    return np.array(all_conf), np.array(all_corr)\n",
        "\n",
        "def calculate_ece(confidences, correct, n_bins=15):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    ece = 0.0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        prop_in_bin = np.mean(in_bin)\n",
        "        if prop_in_bin > 0:\n",
        "            accuracy_in_bin = np.mean(correct[in_bin])\n",
        "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
        "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "    return ece * 100\n",
        "\n",
        "def plot_reliability_diagram(confidences, correct, n_bins, model_name, suffix):\n",
        "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]\n",
        "    bin_accs, bin_confs, bin_props = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
        "    for i, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
        "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
        "        bin_props[i] = np.mean(in_bin)\n",
        "        if bin_props[i] > 0:\n",
        "            bin_accs[i] = np.mean(correct[in_bin])\n",
        "            bin_confs[i] = np.mean(confidences[in_bin])\n",
        "    plt.figure(figsize=(8, 7))\n",
        "    bar_width, bar_centers = 1.0 / n_bins, bin_lowers + 1.0 / (2 * n_bins)\n",
        "    non_empty = bin_props > 0\n",
        "    plt.bar(bar_centers[non_empty], bin_accs[non_empty], width=bar_width*0.9, alpha=0.3, color='red', edgecolor='red', label='Accuracy')\n",
        "    plt.bar(bar_centers[non_empty], (bin_confs - bin_accs)[non_empty], bottom=bin_accs[non_empty], width=bar_width*0.9, alpha=0.5, color='blue', edgecolor='black', label='Confidence Gap')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "    plt.xlabel('Confidence'); plt.ylabel('Accuracy'); plt.title(f'Reliability Diagram: {model_name} ({suffix})')\n",
        "    plt.legend(); plt.xlim(0, 1); plt.ylim(0, 1); plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    save_folder = \"/content/cifar-10-ls-scratch\" # New folder for this experiment\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    filename = f\"{save_folder}/{model_name.replace(' ', '_')}_C10_reliability_{suffix}.png\"\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    print(f\" Saved reliability diagram: {filename}\")\n",
        "\n",
        "# --- NEW: Training Function ---\n",
        "def train_with_ls(model, train_loader, test_loader, epochs=50, lr=0.1, smoothing=0.1):\n",
        "    print(f\"\\n--- Starting training from scratch with Label Smoothing (={smoothing}) ---\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Loss function with label smoothing\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
        "\n",
        "    # Optimizer (SGD with momentum is standard for ResNets on CIFAR)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation accuracy check\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            # You could save the best model checkpoint here\n",
        "\n",
        "        print(f\"Epoch {epoch+1:02}/{epochs} | Loss: {running_loss / len(train_loader):.4f} | Test Acc: {acc:.2f}% (Best: {best_acc:.2f}%)\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f\"--- Training complete. Best Test Accuracy: {best_acc:.2f}% ---\")\n",
        "    return model # Return the model from the final epoch\n",
        "\n",
        "# --- NEW: Evaluation Function ---\n",
        "def evaluate_model(model, model_name, n_bins=15):\n",
        "    print(f\"\\n--- Evaluating model: {model_name} (at T=1.0) ---\")\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # Evaluate with T=1.0 (no post-hoc scaling)\n",
        "    conf, corr = get_predictions(model, test_loader, device, temp=1.0)\n",
        "    ece = calculate_ece(conf, corr, n_bins=n_bins)\n",
        "    acc = np.mean(corr) * 100\n",
        "    avg_conf = np.mean(conf) * 100\n",
        "\n",
        "    print(f\"Test metrics  Acc: {acc:.2f}%, Avg Conf: {avg_conf:.2f}%, ECE: {ece:.3f}%\")\n",
        "    plot_reliability_diagram(conf, corr, n_bins, model_name, \"ls_scratch\")\n",
        "\n",
        "    return {\"name\": model_name, \"acc\": acc, \"ece\": ece, \"conf\": avg_conf}\n",
        "\n",
        "\n",
        "# =======================================================\n",
        "# --- RUN TRAINING & EVALUATION ---\n",
        "# =======================================================\n",
        "all_results = []\n",
        "try:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Running training from scratch for ResNet-56 (w/ LS)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Create a new, from-scratch model\n",
        "    model_resnet56_ls = torch.hub.load(\n",
        "        \"chenyaofo/pytorch-cifar-models\",\n",
        "        \"cifar10_resnet56\",\n",
        "        pretrained=False,  # This is the key change\n",
        "        trust_repo=True\n",
        "    )\n",
        "\n",
        "    # 2. Train it\n",
        "    # Pass the new model to the training function\n",
        "    trained_model = train_with_ls(model_resnet56_ls, train_loader, test_loader, epochs=50)\n",
        "\n",
        "    # 3. Evaluate the trained model\n",
        "    # Change the name for clear labeling in plots and tables\n",
        "    results = evaluate_model(trained_model, \"ResNet-56 (LS Scratch)\")\n",
        "    all_results.append(results)\n",
        "\n",
        "except ImportError:\n",
        "    print(\" ERROR: Could not import `models.cifar.resnet`. Make sure the model file is available.\")\n",
        "except Exception as e:\n",
        "    print(f\" An error occurred during training or evaluation: {e}\")\n",
        "\n",
        "# --- FINAL TABLE ---\n",
        "if all_results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" Final Results for Training from Scratch with Label Smoothing\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"{'Model':<28} | {'Accuracy':>10} | {'ECE':>15} | {'Avg Conf':>15}\")\n",
        "    print(\"-\" * 80)\n",
        "    for r in all_results:\n",
        "        print(f\"{r['name']:<28} | {r['acc']:>9.2f}% | {r['ece']:>14.4f}% | {r['conf']:>14.2f}%\")\n",
        "    print(\"=\" * 80)\n",
        "else:\n",
        "    print(\"\\nNo models were successfully trained.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB5OtMPFCoYV",
        "outputId": "c5fa4941-ec23-41c1-f455-3c6fbb928f98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading CIFAR-10 data...\n",
            "Data loaded: 50000 train, 10000 test samples.\n",
            "\n",
            "============================================================\n",
            "Running training from scratch for ResNet-56 (w/ LS)\n",
            "============================================================\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "\n",
            "--- Starting training from scratch with Label Smoothing (=0.1) ---\n",
            "Epoch 01/50 | Loss: 1.9505 | Test Acc: 42.20% (Best: 42.20%)\n",
            "Epoch 02/50 | Loss: 1.5240 | Test Acc: 54.10% (Best: 54.10%)\n",
            "Epoch 03/50 | Loss: 1.2734 | Test Acc: 63.68% (Best: 63.68%)\n",
            "Epoch 04/50 | Loss: 1.1478 | Test Acc: 68.81% (Best: 68.81%)\n",
            "Epoch 05/50 | Loss: 1.0710 | Test Acc: 74.66% (Best: 74.66%)\n",
            "Epoch 06/50 | Loss: 1.0288 | Test Acc: 70.51% (Best: 74.66%)\n",
            "Epoch 07/50 | Loss: 0.9946 | Test Acc: 71.01% (Best: 74.66%)\n",
            "Epoch 08/50 | Loss: 0.9750 | Test Acc: 74.94% (Best: 74.94%)\n",
            "Epoch 09/50 | Loss: 0.9525 | Test Acc: 61.02% (Best: 74.94%)\n",
            "Epoch 10/50 | Loss: 0.9353 | Test Acc: 76.77% (Best: 76.77%)\n",
            "Epoch 11/50 | Loss: 0.9263 | Test Acc: 78.62% (Best: 78.62%)\n",
            "Epoch 12/50 | Loss: 0.9101 | Test Acc: 81.91% (Best: 81.91%)\n",
            "Epoch 13/50 | Loss: 0.9019 | Test Acc: 63.97% (Best: 81.91%)\n",
            "Epoch 14/50 | Loss: 0.8870 | Test Acc: 79.35% (Best: 81.91%)\n",
            "Epoch 15/50 | Loss: 0.8761 | Test Acc: 79.72% (Best: 81.91%)\n",
            "Epoch 16/50 | Loss: 0.8634 | Test Acc: 81.52% (Best: 81.91%)\n",
            "Epoch 17/50 | Loss: 0.8527 | Test Acc: 78.48% (Best: 81.91%)\n",
            "Epoch 18/50 | Loss: 0.8470 | Test Acc: 81.97% (Best: 81.97%)\n",
            "Epoch 19/50 | Loss: 0.8438 | Test Acc: 82.64% (Best: 82.64%)\n",
            "Epoch 20/50 | Loss: 0.8286 | Test Acc: 79.42% (Best: 82.64%)\n",
            "Epoch 21/50 | Loss: 0.8225 | Test Acc: 77.97% (Best: 82.64%)\n",
            "Epoch 22/50 | Loss: 0.8093 | Test Acc: 78.57% (Best: 82.64%)\n",
            "Epoch 23/50 | Loss: 0.8023 | Test Acc: 81.96% (Best: 82.64%)\n",
            "Epoch 24/50 | Loss: 0.7963 | Test Acc: 81.77% (Best: 82.64%)\n",
            "Epoch 25/50 | Loss: 0.7810 | Test Acc: 82.72% (Best: 82.72%)\n",
            "Epoch 26/50 | Loss: 0.7694 | Test Acc: 84.88% (Best: 84.88%)\n",
            "Epoch 27/50 | Loss: 0.7660 | Test Acc: 85.68% (Best: 85.68%)\n",
            "Epoch 28/50 | Loss: 0.7517 | Test Acc: 84.78% (Best: 85.68%)\n",
            "Epoch 29/50 | Loss: 0.7423 | Test Acc: 85.75% (Best: 85.75%)\n",
            "Epoch 30/50 | Loss: 0.7304 | Test Acc: 87.50% (Best: 87.50%)\n",
            "Epoch 31/50 | Loss: 0.7213 | Test Acc: 87.62% (Best: 87.62%)\n",
            "Epoch 32/50 | Loss: 0.7100 | Test Acc: 87.19% (Best: 87.62%)\n",
            "Epoch 33/50 | Loss: 0.6975 | Test Acc: 87.89% (Best: 87.89%)\n",
            "Epoch 34/50 | Loss: 0.6880 | Test Acc: 86.08% (Best: 87.89%)\n",
            "Epoch 35/50 | Loss: 0.6705 | Test Acc: 89.36% (Best: 89.36%)\n",
            "Epoch 36/50 | Loss: 0.6600 | Test Acc: 88.36% (Best: 89.36%)\n",
            "Epoch 37/50 | Loss: 0.6503 | Test Acc: 88.84% (Best: 89.36%)\n",
            "Epoch 38/50 | Loss: 0.6345 | Test Acc: 89.28% (Best: 89.36%)\n",
            "Epoch 39/50 | Loss: 0.6236 | Test Acc: 90.47% (Best: 90.47%)\n",
            "Epoch 40/50 | Loss: 0.6089 | Test Acc: 91.39% (Best: 91.39%)\n",
            "Epoch 41/50 | Loss: 0.5951 | Test Acc: 90.54% (Best: 91.39%)\n",
            "Epoch 42/50 | Loss: 0.5827 | Test Acc: 91.73% (Best: 91.73%)\n",
            "Epoch 43/50 | Loss: 0.5717 | Test Acc: 91.70% (Best: 91.73%)\n",
            "Epoch 44/50 | Loss: 0.5610 | Test Acc: 92.38% (Best: 92.38%)\n",
            "Epoch 45/50 | Loss: 0.5507 | Test Acc: 92.51% (Best: 92.51%)\n",
            "Epoch 46/50 | Loss: 0.5440 | Test Acc: 92.76% (Best: 92.76%)\n",
            "Epoch 47/50 | Loss: 0.5388 | Test Acc: 92.78% (Best: 92.78%)\n",
            "Epoch 48/50 | Loss: 0.5351 | Test Acc: 92.88% (Best: 92.88%)\n",
            "Epoch 49/50 | Loss: 0.5341 | Test Acc: 92.91% (Best: 92.91%)\n",
            "Epoch 50/50 | Loss: 0.5324 | Test Acc: 92.90% (Best: 92.91%)\n",
            "--- Training complete. Best Test Accuracy: 92.91% ---\n",
            "\n",
            "--- Evaluating model: ResNet-56 (LS Scratch) (at T=1.0) ---\n",
            "Test metrics  Acc: 92.90%, Avg Conf: 88.57%, ECE: 6.047%\n",
            " Saved reliability diagram: /content/cifar-10-ls-scratch/ResNet-56_(LS_Scratch)_C10_reliability_ls_scratch.png\n",
            "\n",
            "================================================================================\n",
            " Final Results for Training from Scratch with Label Smoothing\n",
            "================================================================================\n",
            "Model                        |   Accuracy |             ECE |        Avg Conf\n",
            "--------------------------------------------------------------------------------\n",
            "ResNet-56 (LS Scratch)       |     92.90% |         6.0467% |          88.57%\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Model's ECE is High Because Its Accuracy is Low\n",
        "\n",
        "The ECE from your \"LS Scratch\" training (6.05%) is significantly worse than our original, uncalibrated model's ECE (3.96%).\n",
        "\n",
        "The reason is simple: **our new model (92.90% acc) is substantially less accurate than our original model (94.12% acc).**\n",
        "\n",
        "Since **ECE measures the gap between accuracy and confidence**, a large drop in accuracy will almost always increase ECE, as the model's confidences no longer match its (new, lower) correctness.\n",
        "\n",
        "---\n",
        "\n",
        "## Why the New Training Run Performed Worse\n",
        "\n",
        "This isn't a failure of Label Smoothing (LS) as a method. It's a failure of this specific training run to match the performance of the original, expertly-tuned model.\n",
        "\n",
        "1.  **Original Model (94.12% Acc):** The `ResNet-56 (Hub)` model was likely trained by experts for 200-300+ epochs with a perfectly tuned learning rate schedule. It represents a \"best-case\" scenario for accuracy.\n",
        "2.  **Our New LS Model (92.90% Acc):** Oour script trained a new model from scratch for only **50 epochs**. This is not enough time to reach peak performance, especially when using a strong regularizer like Label Smoothing, which often requires *more* training epochs, not fewer.\n",
        "\n",
        "Because oour new model is 1.22% less accurate, its confidences (88.57%) are now \"miscalibrated\" relative to its new, lower accuracy, leading to a high ECE.\n",
        "\n",
        "---\n",
        "\n",
        "## What This Experiment Proves \n",
        "\n",
        "This result is excellent because it provides more strong evidence for our first experiment:\n",
        "\n",
        "**For a high-performing, pre-trained model, Temperature Scaling is the clear winner.**\n",
        "\n",
        "* **Temperature Scaling (TS):** We took our **best** model (94.12% acc) and perfectly calibrated it (ECE: 1.21%) in just a few seconds. This was fast, safe, and mathematically optimal.\n",
        "* **Label Smoothing (LS) Re-training:** We attempted to re-train a model to achieve the same goal. This was slow, difficult, and ultimately resulted in a *worse* model (92.90% acc) with *worse* calibration (ECE: 6.05%)."
      ],
      "metadata": {
        "id": "oOwQPCkZj474"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UhVPesnPj2UV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}