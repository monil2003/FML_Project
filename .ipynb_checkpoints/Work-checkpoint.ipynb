{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acbb793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-classification'...\n",
      "remote: Enumerating objects: 287, done.\u001b[K\n",
      "remote: Total 287 (delta 0), reused 0 (delta 0), pack-reused 287 (from 1)\u001b[K\n",
      "Receiving objects: 100% (287/287), 440.37 KiB | 1.73 MiB/s, done.\n",
      "Resolving deltas: 100% (167/167), done.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SETUP ---\n",
    "# Clone the repository to get the model architecture files\n",
    "!git clone https://github.com/bearpaw/pytorch-classification.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bd3d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/monil/Desktop/Work/FML/Project/pytorch-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Change directory\n",
    "%cd pytorch-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99f778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar.py  imagenet.py  LICENSE  \u001b[0m\u001b[01;34mmodels\u001b[0m/  README.md  TRAINING.md  \u001b[01;34mutils\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dcee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 169M/169M [02:39<00:00, 1.06MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 test data loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F # <-- Added for softmax\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Import all the model architectures we need\n",
    "from models.cifar import resnet\n",
    "from models.cifar.densenet import densenet, Bottleneck\n",
    "from models.cifar.wrn import WideResNet\n",
    "\n",
    "# Setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"==> Using device: {device}\")\n",
    "\n",
    "\n",
    "# --- 2. LOAD CIFAR-100 TEST DATA ---\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "test_dataset_full = datasets.CIFAR100(root='../data', train=False, download=True, transform=transform_test)\n",
    "# Using the full test set for final validation\n",
    "test_loader = DataLoader(test_dataset_full, batch_size=100, shuffle=False, num_workers=2)\n",
    "print(\"CIFAR-100 test data loaded.\")\n",
    "\n",
    "\n",
    "# --- 3. REUSABLE VALIDATION FUNCTION (MODIFIED) ---\n",
    "def validate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_confidence = 0.0 # New: variable to sum confidences\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # --- New: Calculate confidence ---\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            confidences, predicted = torch.max(probabilities, 1)\n",
    "            total_confidence += confidences.sum().item()\n",
    "\n",
    "            # --- Original: Calculate accuracy ---\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    # --- New: Calculate average confidence ---\n",
    "    avg_confidence = 100 * total_confidence / total\n",
    "    return accuracy, avg_confidence # Return both values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a5b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. LOAD AND VALIDATE ResNet-164 ---\n",
    "print(\"\\n--- Validating ResNet-164 ---\")\n",
    "try:\n",
    "    model_resnet = resnet(depth=164, num_classes=100, block_name='Bottleneck').to(device)\n",
    "    checkpoint_path_resnet = '/home/monil/Desktop/Work/FML/Project/resnet164Cifar100/model_best.pth.tar' # Make sure this path is correct\n",
    "    checkpoint = torch.load(checkpoint_path_resnet, map_location=device, weights_only=False)\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    new_state_dict = OrderedDict((k.replace('module.', ''), v) for k, v in state_dict.items())\n",
    "    model_resnet.load_state_dict(new_state_dict)\n",
    "\n",
    "    # --- Updated: Get both accuracy and confidence ---\n",
    "    accuracy, avg_conf = validate_model(model_resnet, test_loader, device)\n",
    "    print(f\" ResNet-164 Accuracy: {accuracy:.2f}% | Avg. Confidence: {avg_conf:.2f}%\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\" Could not find ResNet checkpoint at: {checkpoint_path_resnet}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. LOAD AND VALIDATE DenseNet-100 ---\n",
    "print(\"\\n--- Validating DenseNet-100 ---\")\n",
    "try:\n",
    "    model_densenet = densenet(depth=190, num_classes=100, growthRate=40, compressionRate=2, block=Bottleneck).to(device)\n",
    "    checkpoint_path_densenet = '/home/monil/Desktop/Work/FML/Project/densenet190Cifar100/model_best.pth.tar' # Make sure this path is correct\n",
    "    checkpoint = torch.load(checkpoint_path_densenet, map_location=device, weights_only=False)\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    new_state_dict = OrderedDict((k.replace('module.', ''), v) for k, v in state_dict.items())\n",
    "    model_densenet.load_state_dict(new_state_dict)\n",
    "\n",
    "    # --- Updated: Get both accuracy and confidence ---\n",
    "    accuracy, avg_conf = validate_model(model_densenet, test_loader, device)\n",
    "    print(f\" DenseNet-100 Accuracy: {accuracy:.2f}% | Avg. Confidence: {avg_conf:.2f}%\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\" Could not find DenseNet checkpoint at: {checkpoint_path_densenet}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. LOAD AND VALIDATE ResNet-56 from torch.hub ---\n",
    "print(\"\\n--- Validating ResNet-56 (from torch.hub) ---\")\n",
    "try:\n",
    "    model_hub = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_resnet56\", pretrained=True, trust_repo=True).to(device)\n",
    "\n",
    "    # --- Updated: Get both accuracy and confidence ---\n",
    "    accuracy, avg_conf = validate_model(model_hub, test_loader, device)\n",
    "    print(f\" ResNet-56 Accuracy: {accuracy:.2f}% | Avg. Confidence: {avg_conf:.2f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Could not load torch.hub model. Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd62e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. LOAD AND VALIDATE Wide ResNet-28-10 ---\n",
    "print(\"\\n--- Validating Wide ResNet-28-10 ---\")\n",
    "try:\n",
    "    model_wrn = WideResNet(depth=28, num_classes=100, widen_factor=10, dropRate=0.3).to(device)\n",
    "    checkpoint_path_wrn = '/home/monil/Desktop/Work/FML/Project/WRNCifar100/model_best.pth.tar' # Make sure this path is correct\n",
    "    checkpoint = torch.load(checkpoint_path_wrn, map_location=device, weights_only=False)\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    new_state_dict = OrderedDict((k.replace('module.', ''), v) for k, v in state_dict.items())\n",
    "    model_wrn.load_state_dict(new_state_dict)\n",
    "\n",
    "    # --- Updated: Get both accuracy and confidence ---\n",
    "    accuracy, avg_conf = validate_model(model_wrn, test_loader, device)\n",
    "    print(f\" Wide ResNet-28-10 Accuracy: {accuracy:.2f}% | Avg. Confidence: {avg_conf:.2f}%\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\" Could not find Wide ResNet checkpoint at: {checkpoint_path_wrn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
